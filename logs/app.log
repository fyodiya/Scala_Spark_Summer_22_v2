2022-07-19 19:43:46,173 WARN o.a.h.u.Shell [main] Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems
2022-07-19 19:43:46,195 WARN o.a.h.u.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-07-19 19:43:58,316 WARN o.a.s.e.ProcfsMetricsGetter [executor-heartbeater] Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
2022-07-19 19:51:05,117 WARN o.a.h.u.Shell [main] Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems
2022-07-19 19:51:05,141 WARN o.a.h.u.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-07-19 19:51:06,435 WARN o.a.s.u.Utils [main] Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2022-07-19 19:59:43,111 WARN o.a.h.u.Shell [main] Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems
2022-07-19 19:59:43,133 WARN o.a.h.u.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-07-19 19:59:44,540 WARN o.a.s.u.Utils [main] Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2022-07-19 20:01:54,283 WARN o.a.h.u.Shell [main] Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems
2022-07-19 20:01:54,308 WARN o.a.h.u.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-07-19 20:01:55,710 WARN o.a.s.u.Utils [main] Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2022-07-19 20:02:45,258 WARN o.a.h.u.Shell [main] Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems
2022-07-19 20:02:45,281 WARN o.a.h.u.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-07-19 20:02:46,864 WARN o.a.s.u.Utils [main] Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2022-07-19 20:04:36,345 WARN o.a.h.u.Shell [main] Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems
2022-07-19 20:04:36,366 WARN o.a.h.u.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-07-19 20:04:37,659 WARN o.a.s.u.Utils [main] Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2022-07-19 20:09:15,185 WARN o.a.h.u.Shell [main] Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems
2022-07-19 20:09:15,219 WARN o.a.h.u.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-07-19 20:09:16,676 WARN o.a.s.u.Utils [main] Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2022-07-19 20:21:17,578 WARN o.a.h.u.Shell [main] Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems
2022-07-19 20:21:17,604 WARN o.a.h.u.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-07-19 20:21:19,042 WARN o.a.s.u.Utils [main] Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2022-07-19 21:09:26,823 WARN o.a.h.u.Shell [main] Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems
2022-07-19 21:09:26,848 WARN o.a.h.u.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-07-19 21:09:28,456 WARN o.a.s.u.Utils [main] Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2022-07-19 21:10:11,993 WARN o.a.h.u.Shell [main] Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems
2022-07-19 21:10:12,013 WARN o.a.h.u.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-07-19 21:10:13,536 WARN o.a.s.u.Utils [main] Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2022-07-19 21:10:21,217 ERROR o.a.s.ContextCleaner [Spark Context Cleaner] Error cleaning shuffle 0
java.lang.NullPointerException: null
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1(MapOutputTracker.scala:882) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1$adapted(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.MapOutputTrackerMaster.unregisterShuffle(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner.doCleanupShuffle(ContextCleaner.scala:241) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner.$anonfun$keepCleaning$3(ContextCleaner.scala:202) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner.$anonfun$keepCleaning$3$adapted(ContextCleaner.scala:195) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.ContextCleaner.$anonfun$keepCleaning$1(ContextCleaner.scala:195) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1446) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner.org$apache$spark$ContextCleaner$$keepCleaning(ContextCleaner.scala:189) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner$$anon$1.run(ContextCleaner.scala:79) ~[spark-core_2.13-3.3.0.jar:3.3.0]
2022-07-19 21:10:55,618 WARN o.a.h.u.Shell [main] Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems
2022-07-19 21:10:55,640 WARN o.a.h.u.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-07-19 21:10:56,993 WARN o.a.s.u.Utils [main] Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2022-07-19 21:11:25,028 WARN o.a.h.u.Shell [main] Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems
2022-07-19 21:11:25,050 WARN o.a.h.u.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-07-19 21:11:26,420 WARN o.a.s.u.Utils [main] Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2022-07-19 21:11:47,874 WARN o.a.h.u.Shell [main] Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems
2022-07-19 21:11:47,906 WARN o.a.h.u.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-07-19 21:11:49,341 WARN o.a.s.u.Utils [main] Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2022-07-19 21:14:10,068 WARN o.a.h.u.Shell [main] Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems
2022-07-19 21:14:10,094 WARN o.a.h.u.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-07-19 21:14:11,586 WARN o.a.s.u.Utils [main] Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2022-07-19 21:18:31,913 WARN o.a.h.u.Shell [main] Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems
2022-07-19 21:18:31,937 WARN o.a.h.u.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-07-19 21:18:33,381 WARN o.a.s.u.Utils [main] Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2022-07-19 21:19:50,303 WARN o.a.h.u.Shell [main] Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems
2022-07-19 21:19:50,326 WARN o.a.h.u.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-07-19 21:19:51,607 WARN o.a.s.u.Utils [main] Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2022-07-19 21:20:29,416 WARN o.a.h.u.Shell [main] Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems
2022-07-19 21:20:29,450 WARN o.a.h.u.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-07-19 21:20:30,820 WARN o.a.s.u.Utils [main] Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2022-07-19 21:23:10,303 WARN o.a.h.u.Shell [main] Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems
2022-07-19 21:23:10,328 WARN o.a.h.u.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-07-19 21:23:11,631 WARN o.a.s.u.Utils [main] Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2022-07-19 21:23:19,113 ERROR o.a.s.s.BlockManagerStorageEndpoint [block-manager-storage-async-thread-pool-10] Error in removing shuffle 0
java.lang.NullPointerException: null
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1(MapOutputTracker.scala:882) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1$adapted(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.MapOutputTrackerMaster.unregisterShuffle(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.storage.BlockManagerStorageEndpoint$$anonfun$receiveAndReply$1.$anonfun$applyOrElse$3(BlockManagerStorageEndpoint.scala:59) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.scala:17) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.storage.BlockManagerStorageEndpoint.$anonfun$doAsync$1(BlockManagerStorageEndpoint.scala:89) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:678) ~[scala-library-2.13.8.jar:?]
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467) ~[scala-library-2.13.8.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_332]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_332]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_332]
2022-07-19 21:23:19,130 WARN o.a.s.s.BlockManagerMaster [block-manager-ask-thread-pool-9] Failed to remove shuffle 0 - null
java.lang.NullPointerException: null
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1(MapOutputTracker.scala:882) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1$adapted(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.MapOutputTrackerMaster.unregisterShuffle(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.storage.BlockManagerStorageEndpoint$$anonfun$receiveAndReply$1.$anonfun$applyOrElse$3(BlockManagerStorageEndpoint.scala:59) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.scala:17) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.storage.BlockManagerStorageEndpoint.$anonfun$doAsync$1(BlockManagerStorageEndpoint.scala:89) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:678) ~[scala-library-2.13.8.jar:?]
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467) ~[scala-library-2.13.8.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_332]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_332]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_332]
2022-07-19 21:30:05,483 WARN o.a.h.u.Shell [main] Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems
2022-07-19 21:30:05,506 WARN o.a.h.u.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-07-19 21:30:06,799 WARN o.a.s.u.Utils [main] Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2022-07-19 21:38:45,172 WARN o.a.h.u.Shell [main] Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems
2022-07-19 21:38:45,197 WARN o.a.h.u.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-07-19 21:38:46,559 WARN o.a.s.u.Utils [main] Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2022-07-19 21:41:57,314 WARN o.a.h.u.Shell [main] Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems
2022-07-19 21:41:57,338 WARN o.a.h.u.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-07-19 21:41:58,593 WARN o.a.s.u.Utils [main] Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2022-07-19 21:42:31,278 WARN o.a.h.u.Shell [main] Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems
2022-07-19 21:42:31,299 WARN o.a.h.u.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-07-19 21:42:32,617 WARN o.a.s.u.Utils [main] Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2022-07-21 14:54:07,545 WARN o.a.h.u.Shell [main] Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems
2022-07-21 14:54:07,576 WARN o.a.h.u.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-07-21 14:54:26,386 WARN o.a.s.e.ProcfsMetricsGetter [executor-heartbeater] Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
2022-07-21 15:06:19,738 WARN o.a.h.u.Shell [main] Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems
2022-07-21 15:06:19,764 WARN o.a.h.u.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-07-21 15:06:36,549 WARN o.a.s.e.ProcfsMetricsGetter [executor-heartbeater] Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
2022-07-21 15:14:49,579 WARN o.a.h.u.Shell [main] Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems
2022-07-21 15:14:49,600 WARN o.a.h.u.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-07-21 15:15:51,001 WARN o.a.h.u.Shell [main] Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems
2022-07-21 15:15:51,019 WARN o.a.h.u.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-07-21 15:17:51,272 WARN o.a.h.u.Shell [main] Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems
2022-07-21 15:17:51,292 WARN o.a.h.u.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-07-21 15:21:13,106 WARN o.a.h.u.Shell [main] Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems
2022-07-21 15:21:13,128 WARN o.a.h.u.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-07-21 15:23:02,023 WARN o.a.h.u.Shell [main] Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems
2022-07-21 15:23:02,053 WARN o.a.h.u.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-07-21 19:02:38,395 WARN o.a.h.u.Shell [main] Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems
2022-07-21 19:02:38,427 WARN o.a.h.u.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-07-21 19:08:49,858 WARN o.a.h.u.Shell [main] Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems
2022-07-21 19:08:49,883 WARN o.a.h.u.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-07-21 19:09:09,994 WARN o.a.s.e.ProcfsMetricsGetter [executor-heartbeater] Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
2022-07-21 19:20:50,199 WARN o.a.h.u.Shell [main] Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems
2022-07-21 19:20:50,223 WARN o.a.h.u.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-07-21 19:21:05,918 WARN o.a.s.e.ProcfsMetricsGetter [executor-heartbeater] Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
2022-07-21 19:22:22,822 WARN o.a.h.u.Shell [main] Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems
2022-07-21 19:22:22,844 WARN o.a.h.u.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-07-21 19:22:35,833 WARN o.a.s.e.ProcfsMetricsGetter [executor-heartbeater] Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
2022-07-21 19:24:12,049 WARN o.a.h.u.Shell [main] Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems
2022-07-21 19:24:12,070 WARN o.a.h.u.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-07-21 19:24:25,637 WARN o.a.s.e.ProcfsMetricsGetter [executor-heartbeater] Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
2022-07-21 19:24:56,379 WARN o.a.h.u.Shell [main] Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems
2022-07-21 19:24:56,401 WARN o.a.h.u.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-07-21 19:25:10,311 WARN o.a.s.e.ProcfsMetricsGetter [driver-heartbeater] Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
2022-07-21 19:25:27,603 WARN o.a.h.u.Shell [main] Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems
2022-07-21 19:25:27,626 WARN o.a.h.u.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-07-21 19:26:12,412 WARN o.a.h.u.Shell [main] Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems
2022-07-21 19:26:12,435 WARN o.a.h.u.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-07-21 19:26:24,412 WARN o.a.s.e.ProcfsMetricsGetter [driver-heartbeater] Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
2022-07-21 19:28:36,906 WARN o.a.h.u.Shell [main] Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems
2022-07-21 19:28:36,930 WARN o.a.h.u.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-07-21 19:28:50,545 WARN o.a.h.u.Shell [main] Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems
2022-07-21 19:28:50,566 WARN o.a.h.u.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-07-21 19:29:04,341 WARN o.a.s.e.ProcfsMetricsGetter [driver-heartbeater] Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
2022-07-21 19:30:01,208 WARN o.a.h.u.Shell [main] Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems
2022-07-21 19:30:01,230 WARN o.a.h.u.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-07-21 19:30:14,644 WARN o.a.s.e.ProcfsMetricsGetter [executor-heartbeater] Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
2022-07-21 19:31:10,885 WARN o.a.h.u.Shell [main] Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems
2022-07-21 19:31:10,909 WARN o.a.h.u.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-07-21 19:31:22,395 WARN o.a.h.u.Shell [main] Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems
2022-07-21 19:31:22,421 WARN o.a.h.u.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-07-21 19:31:48,539 WARN o.a.h.u.Shell [main] Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems
2022-07-21 19:31:48,562 WARN o.a.h.u.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-07-21 19:34:33,277 WARN o.a.h.u.Shell [main] Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems
2022-07-21 19:34:33,300 WARN o.a.h.u.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-07-21 19:34:50,415 WARN o.a.s.e.ProcfsMetricsGetter [driver-heartbeater] Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
2022-07-21 20:12:20,064 WARN o.a.h.u.Shell [main] Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: Hadoop home directory C:\Users\eafjo\Downloads\apache-maven-3.8.6-bin\apache-maven-3.8.6\bin\hadoop-3.3.1%HADOOP_HOME%\bin does not exist -see https://wiki.apache.org/hadoop/WindowsProblems
2022-07-21 20:12:20,099 WARN o.a.h.u.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-07-21 20:15:52,316 WARN o.a.h.u.Shell [main] Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: Hadoop home directory C:\Users\eafjo\Downloads\apache-maven-3.8.6-bin\apache-maven-3.8.6\bin\%HADOOP_HOME%\bin does not exist -see https://wiki.apache.org/hadoop/WindowsProblems
2022-07-21 20:15:52,342 WARN o.a.h.u.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-07-21 20:26:05,517 WARN o.a.h.u.Shell [main] Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: Hadoop home directory C:\Users\eafjo\Downloads\apache-maven-3.8.6-bin\apache-maven-3.8.6\bin\%HADOOP_HOME%\bin does not exist -see https://wiki.apache.org/hadoop/WindowsProblems
2022-07-21 20:26:05,546 WARN o.a.h.u.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-07-21 20:34:32,795 WARN o.a.h.u.Shell [main] Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: Hadoop home directory C:\Users\eafjo\Downloads\apache-maven-3.8.6-bin\apache-maven-3.8.6\bin\%HADOOP_HOME% does not exist -see https://wiki.apache.org/hadoop/WindowsProblems
2022-07-21 20:34:32,823 WARN o.a.h.u.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-07-21 20:38:37,077 WARN o.a.h.u.Shell [main] Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: Hadoop home directory C:\Users\eafjo\Downloads\apache-maven-3.8.6-bin\apache-maven-3.8.6\bin\%HADOOP_HOME% does not exist -see https://wiki.apache.org/hadoop/WindowsProblems
2022-07-21 20:38:37,103 WARN o.a.h.u.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-07-21 20:42:32,081 WARN o.a.h.u.Shell [main] Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: Hadoop home directory C:\Users\eafjo\Downloads\winutils-master.zip\winutils-master\hadoop-3.3.1\%HADOOP_HOME% does not exist -see https://wiki.apache.org/hadoop/WindowsProblems
2022-07-21 20:42:32,111 WARN o.a.h.u.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-07-22 10:20:55,185 WARN o.a.h.u.Shell [main] Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: Hadoop home directory C:\Users\eafjo\winutils\hadoop-3.3.1\%HADOOP_HOME%\bin does not exist -see https://wiki.apache.org/hadoop/WindowsProblems
2022-07-22 10:20:55,214 WARN o.a.h.u.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-07-22 10:21:12,866 WARN o.a.h.u.Shell [main] Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: Hadoop home directory C:\Users\eafjo\winutils\hadoop-3.3.1\%HADOOP_HOME%\bin does not exist -see https://wiki.apache.org/hadoop/WindowsProblems
2022-07-22 10:21:12,897 WARN o.a.h.u.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-07-22 10:21:27,534 WARN o.a.h.u.Shell [main] Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: Hadoop home directory C:\Users\eafjo\winutils\hadoop-3.3.1\%HADOOP_HOME%\bin does not exist -see https://wiki.apache.org/hadoop/WindowsProblems
2022-07-22 10:21:27,565 WARN o.a.h.u.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-07-22 10:25:12,701 WARN o.a.h.u.Shell [main] Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: Hadoop home directory C:\Users\eafjo\winutils\hadoop-3.3.1\%HADOOP_HOME%\bin does not exist -see https://wiki.apache.org/hadoop/WindowsProblems
2022-07-22 10:25:12,724 WARN o.a.h.u.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-07-22 10:27:31,973 WARN o.a.h.u.Shell [main] Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: Hadoop home directory C:\Users\eafjo\winutils\hadoop-3.3.1\%HADOOP_HOME%\bin does not exist -see https://wiki.apache.org/hadoop/WindowsProblems
2022-07-22 10:27:32,002 WARN o.a.h.u.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-07-22 10:36:48,137 WARN o.a.h.u.Shell [main] Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: Hadoop home directory C:\Users\eafjo\Documents\GitHub\winutils\%HADOOP_HOME%\bin does not exist -see https://wiki.apache.org/hadoop/WindowsProblems
2022-07-22 10:36:48,163 WARN o.a.h.u.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-07-22 10:44:53,264 WARN o.a.h.u.Shell [main] Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: Hadoop home directory C:\Users\eafjo\Documents\GitHub\winutils\%HADOOP_HOME%\bin does not exist -see https://wiki.apache.org/hadoop/WindowsProblems
2022-07-22 10:44:53,295 WARN o.a.h.u.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-07-22 10:57:43,945 WARN o.a.h.u.Shell [main] Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: Hadoop home directory C:\Users\eafjo\Documents\GitHub\winutils\%HADOOP_HOME%\bin does not exist -see https://wiki.apache.org/hadoop/WindowsProblems
2022-07-22 10:57:43,977 WARN o.a.h.u.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-07-22 11:16:46,695 WARN o.a.h.u.Shell [main] Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: Hadoop home directory C:\Users\eafjo\Documents\GitHub\winutils\hadoop-3.3.1\%HADOOP_HOME%\bin does not exist -see https://wiki.apache.org/hadoop/WindowsProblems
2022-07-22 11:16:46,724 WARN o.a.h.u.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-07-22 11:18:50,974 WARN o.a.h.u.Shell [main] Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: Hadoop home directory C:\Users\eafjo\Documents\GitHub\winutils\%HADOOP_HOME%\bin does not exist -see https://wiki.apache.org/hadoop/WindowsProblems
2022-07-22 11:18:51,001 WARN o.a.h.u.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-07-22 11:24:59,163 WARN o.a.h.u.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-07-22 11:28:29,156 WARN o.a.h.u.Shell [main] Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: Hadoop home directory C:\Users\eafjo\Documents\GitHub\winutils\hadoop-3.3.1\%HADOOP_HOME%\bin does not exist -see https://wiki.apache.org/hadoop/WindowsProblems
2022-07-22 11:28:29,182 WARN o.a.h.u.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-07-22 11:30:13,930 WARN o.a.h.u.Shell [main] Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: Hadoop home directory C:\Users\eafjo\Documents\GitHub\winutils\hadoop-3.3.1%HADOOP_HOME%\bin does not exist -see https://wiki.apache.org/hadoop/WindowsProblems
2022-07-22 11:30:13,967 WARN o.a.h.u.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-07-22 11:34:44,217 WARN o.a.h.u.Shell [main] Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: Hadoop home directory C:\Users\eafjo\Documents\GitHub\winutils\hadoop-3.3.1%HADOOP_HOME%\bin does not exist -see https://wiki.apache.org/hadoop/WindowsProblems
2022-07-22 11:34:44,249 WARN o.a.h.u.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-07-22 11:49:29,108 WARN o.a.h.u.Shell [main] Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: Hadoop home directory C:\Users\eafjo\Documents\GitHub\winutils\hadoop-3.3.1%HADOOP_HOME%\bin does not exist -see https://wiki.apache.org/hadoop/WindowsProblems
2022-07-22 11:49:29,140 WARN o.a.h.u.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-07-23 17:51:48,535 WARN o.a.h.u.Shell [main] Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems
2022-07-23 17:51:48,592 WARN o.a.h.u.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-07-24 17:48:04,479 WARN o.a.h.u.Shell [main] Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems
2022-07-24 17:48:04,510 WARN o.a.h.u.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-07-24 17:55:54,500 WARN o.a.h.u.Shell [main] Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems
2022-07-24 17:55:54,524 WARN o.a.h.u.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-07-24 18:06:22,781 WARN o.a.s.e.ProcfsMetricsGetter [executor-heartbeater] Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
2022-07-25 15:45:29,198 WARN o.a.s.e.ProcfsMetricsGetter [executor-heartbeater] Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
2022-07-25 16:17:17,132 WARN o.a.s.e.ProcfsMetricsGetter [executor-heartbeater] Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
2022-07-25 16:19:58,869 WARN o.a.s.e.ProcfsMetricsGetter [driver-heartbeater] Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
2022-07-25 19:57:13,782 WARN o.a.s.e.ProcfsMetricsGetter [executor-heartbeater] Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
2022-07-25 21:12:57,370 ERROR o.a.s.r.n.Inbox [dispatcher-event-loop-0] Ignoring error
java.util.concurrent.RejectedExecutionException: Task org.apache.spark.executor.Executor$TaskRunner@36bd2284 rejected from java.util.concurrent.ThreadPoolExecutor@191688c2[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063) ~[?:1.8.0_332]
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830) ~[?:1.8.0_332]
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1379) ~[?:1.8.0_332]
	at org.apache.spark.executor.Executor.launchTask(Executor.scala:305) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.scheduler.local.LocalEndpoint.$anonfun$reviveOffers$1(LocalSchedulerBackend.scala:93) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.scheduler.local.LocalEndpoint.$anonfun$reviveOffers$1$adapted(LocalSchedulerBackend.scala:91) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.collection.immutable.Vector.foreach(Vector.scala:1856) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.scheduler.local.LocalEndpoint.reviveOffers(LocalSchedulerBackend.scala:91) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$receive$1.applyOrElse(LocalSchedulerBackend.scala:68) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:115) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_332]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_332]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_332]
2022-07-26 20:21:44,284 ERROR o.a.s.e.Executor [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] Exception in task 0.0 in stage 1.0 (TID 1)
java.lang.RuntimeException: Error while encoding: java.lang.RuntimeException: java.lang.Integer is not a valid external type for schema of string
if (assertnotnull(input[0, org.apache.spark.sql.Row, true]).isNullAt) null else staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true]), 0, some), StringType, false), true, false, true) AS some#14
if (assertnotnull(input[0, org.apache.spark.sql.Row, true]).isNullAt) null else staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true]), 1, column), StringType, false), true, false, true) AS column#15
validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true]), 2, names), LongType, false) AS names#16L
	at org.apache.spark.sql.errors.QueryExecutionErrors$.expressionEncodingError(QueryExecutionErrors.scala:1219) ~[spark-catalyst_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.sql.catalyst.encoders.ExpressionEncoder$Serializer.apply(ExpressionEncoder.scala:210) ~[spark-catalyst_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.sql.catalyst.encoders.ExpressionEncoder$Serializer.apply(ExpressionEncoder.scala:193) ~[spark-catalyst_2.13-3.3.0.jar:3.3.0]
	at scala.collection.Iterator$$anon$9.next(Iterator.scala:577) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source) ~[?:?]
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43) ~[spark-sql_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:760) ~[spark-sql_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:364) ~[spark-sql_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:890) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:890) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:329) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.scheduler.Task.run(Task.scala:136) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_332]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_332]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_332]
Caused by: java.lang.RuntimeException: java.lang.Integer is not a valid external type for schema of string
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificUnsafeProjection.StaticInvoke_1$(Unknown Source) ~[?:?]
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificUnsafeProjection.writeFields_0_0$(Unknown Source) ~[?:?]
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificUnsafeProjection.apply(Unknown Source) ~[?:?]
	at org.apache.spark.sql.catalyst.encoders.ExpressionEncoder$Serializer.apply(ExpressionEncoder.scala:207) ~[spark-catalyst_2.13-3.3.0.jar:3.3.0]
	... 19 more
2022-07-26 20:21:44,324 WARN o.a.s.s.TaskSetManager [task-result-getter-1] Lost task 0.0 in stage 1.0 (TID 1) (Fyodiya executor driver): java.lang.RuntimeException: Error while encoding: java.lang.RuntimeException: java.lang.Integer is not a valid external type for schema of string
if (assertnotnull(input[0, org.apache.spark.sql.Row, true]).isNullAt) null else staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true]), 0, some), StringType, false), true, false, true) AS some#14
if (assertnotnull(input[0, org.apache.spark.sql.Row, true]).isNullAt) null else staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true]), 1, column), StringType, false), true, false, true) AS column#15
validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true]), 2, names), LongType, false) AS names#16L
	at org.apache.spark.sql.errors.QueryExecutionErrors$.expressionEncodingError(QueryExecutionErrors.scala:1219)
	at org.apache.spark.sql.catalyst.encoders.ExpressionEncoder$Serializer.apply(ExpressionEncoder.scala:210)
	at org.apache.spark.sql.catalyst.encoders.ExpressionEncoder$Serializer.apply(ExpressionEncoder.scala:193)
	at scala.collection.Iterator$$anon$9.next(Iterator.scala:577)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:760)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:364)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:890)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:890)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:329)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:136)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.lang.RuntimeException: java.lang.Integer is not a valid external type for schema of string
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificUnsafeProjection.StaticInvoke_1$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificUnsafeProjection.writeFields_0_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificUnsafeProjection.apply(Unknown Source)
	at org.apache.spark.sql.catalyst.encoders.ExpressionEncoder$Serializer.apply(ExpressionEncoder.scala:207)
	... 19 more

2022-07-26 20:21:44,324 ERROR o.a.s.s.TaskSetManager [task-result-getter-1] Task 0 in stage 1.0 failed 1 times; aborting job
2022-07-26 20:23:20,125 ERROR o.a.s.e.Executor [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] Exception in task 0.0 in stage 1.0 (TID 1)
java.lang.RuntimeException: Error while encoding: java.lang.RuntimeException: java.lang.Double is not a valid external type for schema of bigint
if (assertnotnull(input[0, org.apache.spark.sql.Row, true]).isNullAt) null else staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true]), 0, some), StringType, false), true, false, true) AS some#14
if (assertnotnull(input[0, org.apache.spark.sql.Row, true]).isNullAt) null else staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true]), 1, column), StringType, false), true, false, true) AS column#15
validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true]), 2, names), LongType, false) AS names#16L
	at org.apache.spark.sql.errors.QueryExecutionErrors$.expressionEncodingError(QueryExecutionErrors.scala:1219) ~[spark-catalyst_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.sql.catalyst.encoders.ExpressionEncoder$Serializer.apply(ExpressionEncoder.scala:210) ~[spark-catalyst_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.sql.catalyst.encoders.ExpressionEncoder$Serializer.apply(ExpressionEncoder.scala:193) ~[spark-catalyst_2.13-3.3.0.jar:3.3.0]
	at scala.collection.Iterator$$anon$9.next(Iterator.scala:577) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source) ~[?:?]
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43) ~[spark-sql_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:760) ~[spark-sql_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:364) ~[spark-sql_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:890) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:890) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:329) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.scheduler.Task.run(Task.scala:136) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_332]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_332]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_332]
Caused by: java.lang.RuntimeException: java.lang.Double is not a valid external type for schema of bigint
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificUnsafeProjection.writeFields_0_1$(Unknown Source) ~[?:?]
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificUnsafeProjection.apply(Unknown Source) ~[?:?]
	at org.apache.spark.sql.catalyst.encoders.ExpressionEncoder$Serializer.apply(ExpressionEncoder.scala:207) ~[spark-catalyst_2.13-3.3.0.jar:3.3.0]
	... 19 more
2022-07-26 20:23:20,154 WARN o.a.s.s.TaskSetManager [task-result-getter-1] Lost task 0.0 in stage 1.0 (TID 1) (Fyodiya executor driver): java.lang.RuntimeException: Error while encoding: java.lang.RuntimeException: java.lang.Double is not a valid external type for schema of bigint
if (assertnotnull(input[0, org.apache.spark.sql.Row, true]).isNullAt) null else staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true]), 0, some), StringType, false), true, false, true) AS some#14
if (assertnotnull(input[0, org.apache.spark.sql.Row, true]).isNullAt) null else staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true]), 1, column), StringType, false), true, false, true) AS column#15
validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true]), 2, names), LongType, false) AS names#16L
	at org.apache.spark.sql.errors.QueryExecutionErrors$.expressionEncodingError(QueryExecutionErrors.scala:1219)
	at org.apache.spark.sql.catalyst.encoders.ExpressionEncoder$Serializer.apply(ExpressionEncoder.scala:210)
	at org.apache.spark.sql.catalyst.encoders.ExpressionEncoder$Serializer.apply(ExpressionEncoder.scala:193)
	at scala.collection.Iterator$$anon$9.next(Iterator.scala:577)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:760)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:364)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:890)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:890)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:329)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:136)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.lang.RuntimeException: java.lang.Double is not a valid external type for schema of bigint
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificUnsafeProjection.writeFields_0_1$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificUnsafeProjection.apply(Unknown Source)
	at org.apache.spark.sql.catalyst.encoders.ExpressionEncoder$Serializer.apply(ExpressionEncoder.scala:207)
	... 19 more

2022-07-26 20:23:20,159 ERROR o.a.s.s.TaskSetManager [task-result-getter-1] Task 0 in stage 1.0 failed 1 times; aborting job
2022-07-28 21:03:57,091 WARN o.a.s.u.Utils [main] Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2022-07-28 21:04:01,998 WARN o.a.s.e.ProcfsMetricsGetter [executor-heartbeater] Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
2022-07-28 21:34:21,816 ERROR o.a.s.s.BlockManagerStorageEndpoint [block-manager-storage-async-thread-pool-57] Error in removing shuffle 13
java.lang.NullPointerException: null
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1(MapOutputTracker.scala:882) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1$adapted(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.MapOutputTrackerMaster.unregisterShuffle(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.storage.BlockManagerStorageEndpoint$$anonfun$receiveAndReply$1.$anonfun$applyOrElse$3(BlockManagerStorageEndpoint.scala:59) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.scala:17) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.storage.BlockManagerStorageEndpoint.$anonfun$doAsync$1(BlockManagerStorageEndpoint.scala:89) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:678) ~[scala-library-2.13.8.jar:?]
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467) ~[scala-library-2.13.8.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_332]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_332]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_332]
2022-07-28 21:34:21,847 WARN o.a.s.s.BlockManagerMaster [block-manager-ask-thread-pool-32] Failed to remove shuffle 13 - null
java.lang.NullPointerException: null
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1(MapOutputTracker.scala:882) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1$adapted(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.MapOutputTrackerMaster.unregisterShuffle(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.storage.BlockManagerStorageEndpoint$$anonfun$receiveAndReply$1.$anonfun$applyOrElse$3(BlockManagerStorageEndpoint.scala:59) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.scala:17) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.storage.BlockManagerStorageEndpoint.$anonfun$doAsync$1(BlockManagerStorageEndpoint.scala:89) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:678) ~[scala-library-2.13.8.jar:?]
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467) ~[scala-library-2.13.8.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_332]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_332]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_332]
2022-07-28 21:39:22,711 WARN o.a.s.e.ProcfsMetricsGetter [driver-heartbeater] Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
2022-07-28 21:54:51,000 ERROR o.a.s.ContextCleaner [Spark Context Cleaner] Error cleaning shuffle 10
java.lang.NullPointerException: null
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1(MapOutputTracker.scala:882) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1$adapted(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.MapOutputTrackerMaster.unregisterShuffle(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner.doCleanupShuffle(ContextCleaner.scala:241) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner.$anonfun$keepCleaning$3(ContextCleaner.scala:202) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner.$anonfun$keepCleaning$3$adapted(ContextCleaner.scala:195) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.ContextCleaner.$anonfun$keepCleaning$1(ContextCleaner.scala:195) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1446) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner.org$apache$spark$ContextCleaner$$keepCleaning(ContextCleaner.scala:189) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner$$anon$1.run(ContextCleaner.scala:79) ~[spark-core_2.13-3.3.0.jar:3.3.0]
2022-07-29 21:56:08,557 WARN o.a.s.e.ProcfsMetricsGetter [executor-heartbeater] Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
2022-07-29 22:01:21,752 ERROR o.a.s.s.BlockManagerStorageEndpoint [block-manager-storage-async-thread-pool-30] Error in removing shuffle 8
java.lang.NullPointerException: null
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1(MapOutputTracker.scala:882) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1$adapted(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.MapOutputTrackerMaster.unregisterShuffle(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.storage.BlockManagerStorageEndpoint$$anonfun$receiveAndReply$1.$anonfun$applyOrElse$3(BlockManagerStorageEndpoint.scala:59) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.scala:17) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.storage.BlockManagerStorageEndpoint.$anonfun$doAsync$1(BlockManagerStorageEndpoint.scala:89) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:678) ~[scala-library-2.13.8.jar:?]
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467) ~[scala-library-2.13.8.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_332]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_332]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_332]
2022-07-29 22:01:21,777 WARN o.a.s.s.BlockManagerMaster [block-manager-ask-thread-pool-16] Failed to remove shuffle 8 - null
java.lang.NullPointerException: null
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1(MapOutputTracker.scala:882) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1$adapted(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.MapOutputTrackerMaster.unregisterShuffle(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.storage.BlockManagerStorageEndpoint$$anonfun$receiveAndReply$1.$anonfun$applyOrElse$3(BlockManagerStorageEndpoint.scala:59) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.scala:17) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.storage.BlockManagerStorageEndpoint.$anonfun$doAsync$1(BlockManagerStorageEndpoint.scala:89) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:678) ~[scala-library-2.13.8.jar:?]
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467) ~[scala-library-2.13.8.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_332]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_332]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_332]
2022-07-29 22:01:22,766 ERROR o.a.s.s.BlockManagerStorageEndpoint [block-manager-storage-async-thread-pool-45] Error in removing shuffle 13
java.lang.NullPointerException: null
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1(MapOutputTracker.scala:882) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1$adapted(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.MapOutputTrackerMaster.unregisterShuffle(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.storage.BlockManagerStorageEndpoint$$anonfun$receiveAndReply$1.$anonfun$applyOrElse$3(BlockManagerStorageEndpoint.scala:59) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.scala:17) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.storage.BlockManagerStorageEndpoint.$anonfun$doAsync$1(BlockManagerStorageEndpoint.scala:89) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:678) ~[scala-library-2.13.8.jar:?]
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467) ~[scala-library-2.13.8.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_332]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_332]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_332]
2022-07-29 22:01:22,766 WARN o.a.s.s.BlockManagerMaster [block-manager-ask-thread-pool-62] Failed to remove shuffle 13 - null
java.lang.NullPointerException: null
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1(MapOutputTracker.scala:882) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1$adapted(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.MapOutputTrackerMaster.unregisterShuffle(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.storage.BlockManagerStorageEndpoint$$anonfun$receiveAndReply$1.$anonfun$applyOrElse$3(BlockManagerStorageEndpoint.scala:59) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.scala:17) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.storage.BlockManagerStorageEndpoint.$anonfun$doAsync$1(BlockManagerStorageEndpoint.scala:89) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:678) ~[scala-library-2.13.8.jar:?]
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467) ~[scala-library-2.13.8.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_332]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_332]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_332]
2022-07-29 22:02:48,702 ERROR o.a.s.ContextCleaner [Spark Context Cleaner] Error cleaning shuffle 6
java.lang.NullPointerException: null
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1(MapOutputTracker.scala:882) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1$adapted(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.MapOutputTrackerMaster.unregisterShuffle(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner.doCleanupShuffle(ContextCleaner.scala:241) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner.$anonfun$keepCleaning$3(ContextCleaner.scala:202) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner.$anonfun$keepCleaning$3$adapted(ContextCleaner.scala:195) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.ContextCleaner.$anonfun$keepCleaning$1(ContextCleaner.scala:195) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1446) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner.org$apache$spark$ContextCleaner$$keepCleaning(ContextCleaner.scala:189) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner$$anon$1.run(ContextCleaner.scala:79) ~[spark-core_2.13-3.3.0.jar:3.3.0]
2022-07-29 22:02:49,745 ERROR o.a.s.s.BlockManagerStorageEndpoint [block-manager-storage-async-thread-pool-92] Error in removing shuffle 14
java.lang.NullPointerException: null
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1(MapOutputTracker.scala:882) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1$adapted(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.MapOutputTrackerMaster.unregisterShuffle(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.storage.BlockManagerStorageEndpoint$$anonfun$receiveAndReply$1.$anonfun$applyOrElse$3(BlockManagerStorageEndpoint.scala:59) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.scala:17) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.storage.BlockManagerStorageEndpoint.$anonfun$doAsync$1(BlockManagerStorageEndpoint.scala:89) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:678) ~[scala-library-2.13.8.jar:?]
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467) ~[scala-library-2.13.8.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_332]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_332]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_332]
2022-07-29 22:02:49,753 WARN o.a.s.s.BlockManagerMaster [block-manager-ask-thread-pool-32] Failed to remove shuffle 14 - null
java.lang.NullPointerException: null
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1(MapOutputTracker.scala:882) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1$adapted(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.MapOutputTrackerMaster.unregisterShuffle(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.storage.BlockManagerStorageEndpoint$$anonfun$receiveAndReply$1.$anonfun$applyOrElse$3(BlockManagerStorageEndpoint.scala:59) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.scala:17) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.storage.BlockManagerStorageEndpoint.$anonfun$doAsync$1(BlockManagerStorageEndpoint.scala:89) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:678) ~[scala-library-2.13.8.jar:?]
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467) ~[scala-library-2.13.8.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_332]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_332]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_332]
2022-07-29 22:03:09,047 ERROR o.a.s.s.BlockManagerStorageEndpoint [block-manager-storage-async-thread-pool-36] Error in removing shuffle 12
java.lang.NullPointerException: null
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1(MapOutputTracker.scala:882) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1$adapted(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.MapOutputTrackerMaster.unregisterShuffle(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.storage.BlockManagerStorageEndpoint$$anonfun$receiveAndReply$1.$anonfun$applyOrElse$3(BlockManagerStorageEndpoint.scala:59) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.scala:17) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.storage.BlockManagerStorageEndpoint.$anonfun$doAsync$1(BlockManagerStorageEndpoint.scala:89) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:678) ~[scala-library-2.13.8.jar:?]
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467) ~[scala-library-2.13.8.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_332]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_332]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_332]
2022-07-29 22:03:09,066 WARN o.a.s.s.BlockManagerMaster [block-manager-ask-thread-pool-22] Failed to remove shuffle 12 - null
java.lang.NullPointerException: null
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1(MapOutputTracker.scala:882) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1$adapted(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.MapOutputTrackerMaster.unregisterShuffle(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.storage.BlockManagerStorageEndpoint$$anonfun$receiveAndReply$1.$anonfun$applyOrElse$3(BlockManagerStorageEndpoint.scala:59) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.scala:17) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.storage.BlockManagerStorageEndpoint.$anonfun$doAsync$1(BlockManagerStorageEndpoint.scala:89) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:678) ~[scala-library-2.13.8.jar:?]
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467) ~[scala-library-2.13.8.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_332]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_332]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_332]
2022-07-29 22:03:10,439 WARN o.a.s.e.ProcfsMetricsGetter [executor-heartbeater] Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
2022-07-29 22:07:52,366 ERROR o.a.s.s.BlockManagerStorageEndpoint [block-manager-storage-async-thread-pool-3] Error in removing shuffle 4
java.lang.NullPointerException: null
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1(MapOutputTracker.scala:882) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1$adapted(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.MapOutputTrackerMaster.unregisterShuffle(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.storage.BlockManagerStorageEndpoint$$anonfun$receiveAndReply$1.$anonfun$applyOrElse$3(BlockManagerStorageEndpoint.scala:59) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.scala:17) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.storage.BlockManagerStorageEndpoint.$anonfun$doAsync$1(BlockManagerStorageEndpoint.scala:89) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:678) ~[scala-library-2.13.8.jar:?]
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467) ~[scala-library-2.13.8.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_332]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_332]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_332]
2022-07-29 22:07:52,390 WARN o.a.s.s.BlockManagerMaster [block-manager-ask-thread-pool-75] Failed to remove shuffle 4 - null
java.lang.NullPointerException: null
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1(MapOutputTracker.scala:882) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1$adapted(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.MapOutputTrackerMaster.unregisterShuffle(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.storage.BlockManagerStorageEndpoint$$anonfun$receiveAndReply$1.$anonfun$applyOrElse$3(BlockManagerStorageEndpoint.scala:59) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.scala:17) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.storage.BlockManagerStorageEndpoint.$anonfun$doAsync$1(BlockManagerStorageEndpoint.scala:89) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:678) ~[scala-library-2.13.8.jar:?]
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467) ~[scala-library-2.13.8.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_332]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_332]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_332]
2022-07-29 22:10:10,973 ERROR o.a.s.ContextCleaner [Spark Context Cleaner] Error cleaning shuffle 7
java.lang.NullPointerException: null
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1(MapOutputTracker.scala:882) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1$adapted(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.MapOutputTrackerMaster.unregisterShuffle(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner.doCleanupShuffle(ContextCleaner.scala:241) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner.$anonfun$keepCleaning$3(ContextCleaner.scala:202) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner.$anonfun$keepCleaning$3$adapted(ContextCleaner.scala:195) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.ContextCleaner.$anonfun$keepCleaning$1(ContextCleaner.scala:195) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1446) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner.org$apache$spark$ContextCleaner$$keepCleaning(ContextCleaner.scala:189) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner$$anon$1.run(ContextCleaner.scala:79) ~[spark-core_2.13-3.3.0.jar:3.3.0]
2022-07-29 22:10:10,994 ERROR o.a.s.ContextCleaner [Spark Context Cleaner] Error cleaning shuffle 10
java.lang.NullPointerException: null
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1(MapOutputTracker.scala:882) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1$adapted(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.MapOutputTrackerMaster.unregisterShuffle(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner.doCleanupShuffle(ContextCleaner.scala:241) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner.$anonfun$keepCleaning$3(ContextCleaner.scala:202) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner.$anonfun$keepCleaning$3$adapted(ContextCleaner.scala:195) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.ContextCleaner.$anonfun$keepCleaning$1(ContextCleaner.scala:195) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1446) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner.org$apache$spark$ContextCleaner$$keepCleaning(ContextCleaner.scala:189) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner$$anon$1.run(ContextCleaner.scala:79) ~[spark-core_2.13-3.3.0.jar:3.3.0]
2022-07-29 22:12:27,266 ERROR o.a.s.s.BlockManagerStorageEndpoint [block-manager-storage-async-thread-pool-83] Error in removing shuffle 8
java.lang.NullPointerException: null
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1(MapOutputTracker.scala:882) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1$adapted(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.MapOutputTrackerMaster.unregisterShuffle(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.storage.BlockManagerStorageEndpoint$$anonfun$receiveAndReply$1.$anonfun$applyOrElse$3(BlockManagerStorageEndpoint.scala:59) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.scala:17) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.storage.BlockManagerStorageEndpoint.$anonfun$doAsync$1(BlockManagerStorageEndpoint.scala:89) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:678) ~[scala-library-2.13.8.jar:?]
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467) ~[scala-library-2.13.8.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_332]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_332]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_332]
2022-07-29 22:12:27,286 WARN o.a.s.s.BlockManagerMaster [block-manager-ask-thread-pool-24] Failed to remove shuffle 8 - null
java.lang.NullPointerException: null
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1(MapOutputTracker.scala:882) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1$adapted(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.MapOutputTrackerMaster.unregisterShuffle(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.storage.BlockManagerStorageEndpoint$$anonfun$receiveAndReply$1.$anonfun$applyOrElse$3(BlockManagerStorageEndpoint.scala:59) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.scala:17) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.storage.BlockManagerStorageEndpoint.$anonfun$doAsync$1(BlockManagerStorageEndpoint.scala:89) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:678) ~[scala-library-2.13.8.jar:?]
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467) ~[scala-library-2.13.8.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_332]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_332]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_332]
2022-07-29 22:13:20,845 ERROR o.a.s.ContextCleaner [Spark Context Cleaner] Error cleaning shuffle 7
java.lang.NullPointerException: null
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1(MapOutputTracker.scala:882) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1$adapted(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.MapOutputTrackerMaster.unregisterShuffle(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner.doCleanupShuffle(ContextCleaner.scala:241) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner.$anonfun$keepCleaning$3(ContextCleaner.scala:202) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner.$anonfun$keepCleaning$3$adapted(ContextCleaner.scala:195) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.ContextCleaner.$anonfun$keepCleaning$1(ContextCleaner.scala:195) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1446) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner.org$apache$spark$ContextCleaner$$keepCleaning(ContextCleaner.scala:189) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner$$anon$1.run(ContextCleaner.scala:79) ~[spark-core_2.13-3.3.0.jar:3.3.0]
2022-07-29 22:13:45,682 WARN o.a.s.e.ProcfsMetricsGetter [executor-heartbeater] Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
2022-07-29 22:25:20,585 ERROR o.a.s.ContextCleaner [Spark Context Cleaner] Error cleaning shuffle 5
java.lang.NullPointerException: null
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1(MapOutputTracker.scala:882) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1$adapted(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.MapOutputTrackerMaster.unregisterShuffle(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner.doCleanupShuffle(ContextCleaner.scala:241) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner.$anonfun$keepCleaning$3(ContextCleaner.scala:202) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner.$anonfun$keepCleaning$3$adapted(ContextCleaner.scala:195) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.ContextCleaner.$anonfun$keepCleaning$1(ContextCleaner.scala:195) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1446) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner.org$apache$spark$ContextCleaner$$keepCleaning(ContextCleaner.scala:189) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner$$anon$1.run(ContextCleaner.scala:79) ~[spark-core_2.13-3.3.0.jar:3.3.0]
2022-07-29 22:29:49,300 ERROR o.a.s.s.DiskBlockManager [shutdown-hook-0] Exception while deleting local spark dir: C:\Users\eafjo\AppData\Local\Temp\blockmgr-10fc0d41-9dc2-4c9d-b68b-67ef2acef1cd
java.io.IOException: Failed to delete: C:\Users\eafjo\AppData\Local\Temp\blockmgr-10fc0d41-9dc2-4c9d-b68b-67ef2acef1cd\35\shuffle_20_56_0.data
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:144) ~[spark-network-common_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118) ~[spark-network-common_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128) ~[spark-network-common_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118) ~[spark-network-common_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128) ~[spark-network-common_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118) ~[spark-network-common_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:91) ~[spark-network-common_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1206) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1(DiskBlockManager.scala:374) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1$adapted(DiskBlockManager.scala:370) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1328) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.storage.DiskBlockManager.doStop(DiskBlockManager.scala:370) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:365) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.storage.BlockManager.stop(BlockManager.scala:2016) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:95) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.SparkContext.$anonfun$stop$23(SparkContext.scala:2140) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1484) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2140) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.SparkContext.$anonfun$new$35(SparkContext.scala:660) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18) ~[scala-library-2.13.8.jar:?]
	at scala.util.Try$.apply(Try.scala:210) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_332]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_332]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_332]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_332]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_332]
2022-08-01 21:28:28,821 WARN o.a.s.e.ProcfsMetricsGetter [executor-heartbeater] Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
2022-08-02 19:20:49,358 WARN o.a.s.u.Utils [main] Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2022-08-08 12:50:51,480 WARN o.a.s.s.c.u.package [main] Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
2022-08-08 12:50:51,532 WARN o.a.s.e.ProcfsMetricsGetter [driver-heartbeater] Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
2022-08-08 12:51:33,163 WARN o.a.s.s.c.u.package [main] Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
2022-08-08 12:51:34,609 WARN o.a.s.e.ProcfsMetricsGetter [executor-heartbeater] Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
2022-08-08 13:13:50,009 WARN o.a.s.s.c.u.package [main] Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
2022-08-08 14:51:25,822 WARN o.a.s.s.c.u.package [main] Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
2022-08-08 14:54:40,318 WARN o.a.s.s.c.u.package [main] Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
2022-08-08 14:58:50,751 WARN o.a.s.s.c.u.package [main] Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
2022-08-08 15:09:26,463 WARN o.a.s.s.c.u.package [main] Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
2022-08-08 15:09:26,721 WARN o.a.s.e.ProcfsMetricsGetter [driver-heartbeater] Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
2022-08-08 15:11:19,552 WARN o.a.s.s.c.u.package [main] Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
2022-08-08 21:29:43,372 WARN o.a.s.s.c.u.package [main] Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
2022-08-08 21:29:43,464 WARN o.a.s.e.ProcfsMetricsGetter [executor-heartbeater] Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
2022-08-08 21:30:22,314 WARN o.a.s.s.c.u.package [main] Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
2022-08-08 21:44:26,144 WARN o.a.s.e.ProcfsMetricsGetter [executor-heartbeater] Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
2022-08-08 21:44:26,441 WARN o.a.s.s.c.u.package [main] Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
2022-08-08 21:48:36,051 WARN o.a.s.e.ProcfsMetricsGetter [driver-heartbeater] Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
2022-08-08 21:48:39,403 WARN o.a.s.s.c.u.package [main] Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
2022-08-08 21:54:10,297 WARN o.a.s.e.ProcfsMetricsGetter [executor-heartbeater] Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
2022-08-08 21:54:13,695 WARN o.a.s.s.c.u.package [main] Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
2022-08-08 21:57:56,646 WARN o.a.s.s.c.u.package [main] Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
2022-08-08 21:57:57,105 WARN o.a.s.e.ProcfsMetricsGetter [driver-heartbeater] Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
2022-08-08 21:59:25,932 WARN o.a.s.e.ProcfsMetricsGetter [executor-heartbeater] Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
2022-08-08 21:59:27,077 WARN o.a.s.s.c.u.package [main] Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
2022-08-08 22:01:10,363 WARN o.a.s.e.ProcfsMetricsGetter [driver-heartbeater] Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
2022-08-08 22:01:14,424 WARN o.a.s.s.c.u.package [main] Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
2022-08-09 21:56:40,537 WARN o.a.s.e.ProcfsMetricsGetter [executor-heartbeater] Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
2022-08-09 21:58:03,102 WARN o.a.s.e.ProcfsMetricsGetter [executor-heartbeater] Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
2022-08-11 11:29:03,752 WARN o.a.s.e.ProcfsMetricsGetter [driver-heartbeater] Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
2022-08-11 11:30:33,689 WARN o.a.s.e.ProcfsMetricsGetter [executor-heartbeater] Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
2022-08-11 11:33:43,006 WARN o.a.s.e.ProcfsMetricsGetter [driver-heartbeater] Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
2022-08-11 11:37:21,006 WARN o.a.s.e.ProcfsMetricsGetter [driver-heartbeater] Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
2022-08-11 12:56:21,649 ERROR o.a.s.s.BlockManagerStorageEndpoint [block-manager-storage-async-thread-pool-10] Error in removing shuffle 0
java.lang.NullPointerException: null
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1(MapOutputTracker.scala:882) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1$adapted(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.MapOutputTrackerMaster.unregisterShuffle(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.storage.BlockManagerStorageEndpoint$$anonfun$receiveAndReply$1.$anonfun$applyOrElse$3(BlockManagerStorageEndpoint.scala:59) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.scala:17) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.storage.BlockManagerStorageEndpoint.$anonfun$doAsync$1(BlockManagerStorageEndpoint.scala:89) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:678) ~[scala-library-2.13.8.jar:?]
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467) ~[scala-library-2.13.8.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_332]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_332]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_332]
2022-08-11 12:56:21,670 WARN o.a.s.s.BlockManagerMaster [block-manager-ask-thread-pool-9] Failed to remove shuffle 0 - null
java.lang.NullPointerException: null
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1(MapOutputTracker.scala:882) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1$adapted(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.MapOutputTrackerMaster.unregisterShuffle(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.storage.BlockManagerStorageEndpoint$$anonfun$receiveAndReply$1.$anonfun$applyOrElse$3(BlockManagerStorageEndpoint.scala:59) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.scala:17) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.storage.BlockManagerStorageEndpoint.$anonfun$doAsync$1(BlockManagerStorageEndpoint.scala:89) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:678) ~[scala-library-2.13.8.jar:?]
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467) ~[scala-library-2.13.8.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_332]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_332]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_332]
2022-08-11 21:38:02,452 WARN o.a.s.u.Utils [main] Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2022-08-11 21:38:03,198 WARN o.a.s.e.ProcfsMetricsGetter [driver-heartbeater] Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
2022-08-11 21:38:15,041 WARN o.a.s.e.ProcfsMetricsGetter [driver-heartbeater] Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
2022-08-11 21:58:12,589 WARN o.a.s.e.ProcfsMetricsGetter [executor-heartbeater] Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
2022-08-12 20:50:10,048 WARN o.a.s.e.ProcfsMetricsGetter [executor-heartbeater] Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
2022-08-12 20:53:14,818 WARN o.a.s.e.ProcfsMetricsGetter [driver-heartbeater] Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
2022-08-12 20:56:54,966 WARN o.a.s.e.ProcfsMetricsGetter [executor-heartbeater] Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
2022-08-12 21:00:04,936 WARN o.a.s.e.ProcfsMetricsGetter [driver-heartbeater] Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
2022-08-12 21:02:10,612 WARN o.a.s.e.ProcfsMetricsGetter [executor-heartbeater] Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
2022-08-12 21:03:20,470 WARN o.a.s.e.ProcfsMetricsGetter [executor-heartbeater] Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
2022-08-12 21:08:23,177 WARN o.a.s.e.ProcfsMetricsGetter [executor-heartbeater] Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
2022-08-12 21:08:24,476 WARN o.a.s.s.c.u.package [main] Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
2022-08-12 21:10:46,677 WARN o.a.s.e.ProcfsMetricsGetter [executor-heartbeater] Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
2022-08-12 21:10:50,631 WARN o.a.s.s.c.u.package [main] Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
2022-08-13 10:31:44,998 WARN o.a.s.e.ProcfsMetricsGetter [executor-heartbeater] Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
2022-08-13 10:33:57,767 WARN o.a.s.e.ProcfsMetricsGetter [executor-heartbeater] Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
2022-08-13 10:42:39,372 WARN o.a.s.e.ProcfsMetricsGetter [executor-heartbeater] Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
2022-08-13 10:44:41,123 WARN o.a.s.e.ProcfsMetricsGetter [executor-heartbeater] Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
2022-08-13 10:46:10,744 WARN o.a.s.e.ProcfsMetricsGetter [executor-heartbeater] Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
2022-08-13 10:52:42,405 WARN o.a.s.e.ProcfsMetricsGetter [driver-heartbeater] Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
2022-08-13 10:55:32,405 WARN o.a.s.e.ProcfsMetricsGetter [executor-heartbeater] Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
2022-08-13 11:15:00,111 WARN o.a.s.u.Utils [main] Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2022-08-13 11:15:12,050 WARN o.a.s.e.ProcfsMetricsGetter [executor-heartbeater] Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
2022-08-13 11:15:13,661 ERROR o.a.s.s.BlockManagerStorageEndpoint [block-manager-storage-async-thread-pool-8] Error in removing shuffle 1
java.lang.NullPointerException: null
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1(MapOutputTracker.scala:882) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1$adapted(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.MapOutputTrackerMaster.unregisterShuffle(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.storage.BlockManagerStorageEndpoint$$anonfun$receiveAndReply$1.$anonfun$applyOrElse$3(BlockManagerStorageEndpoint.scala:59) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.scala:17) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.storage.BlockManagerStorageEndpoint.$anonfun$doAsync$1(BlockManagerStorageEndpoint.scala:89) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:678) ~[scala-library-2.13.8.jar:?]
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467) ~[scala-library-2.13.8.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_332]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_332]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_332]
2022-08-13 11:15:13,680 WARN o.a.s.s.BlockManagerMaster [block-manager-ask-thread-pool-75] Failed to remove shuffle 1 - null
java.lang.NullPointerException: null
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1(MapOutputTracker.scala:882) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1$adapted(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.MapOutputTrackerMaster.unregisterShuffle(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.storage.BlockManagerStorageEndpoint$$anonfun$receiveAndReply$1.$anonfun$applyOrElse$3(BlockManagerStorageEndpoint.scala:59) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.scala:17) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.storage.BlockManagerStorageEndpoint.$anonfun$doAsync$1(BlockManagerStorageEndpoint.scala:89) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:678) ~[scala-library-2.13.8.jar:?]
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467) ~[scala-library-2.13.8.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_332]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_332]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_332]
2022-08-13 11:58:49,833 WARN o.a.s.e.ProcfsMetricsGetter [driver-heartbeater] Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
2022-08-13 12:19:02,478 WARN o.a.s.e.ProcfsMetricsGetter [driver-heartbeater] Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
2022-08-15 10:36:57,857 WARN o.a.s.s.c.u.ParseMode [main] OVERWRITE is not a valid parse mode. Using PERMISSIVE.
2022-08-15 10:45:35,905 WARN o.a.s.s.SparkSession [main] Using an existing Spark session; only runtime SQL configurations will take effect.
2022-08-15 10:52:09,639 WARN o.a.s.s.SparkSession [main] Using an existing Spark session; only runtime SQL configurations will take effect.
2022-08-15 11:16:47,461 WARN o.a.s.s.SparkSession [main] Using an existing Spark session; only runtime SQL configurations will take effect.
2022-08-15 16:17:16,177 WARN o.a.p.CorruptStatistics [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] Ignoring statistics because created_by could not be parsed (see PARQUET-251): parquet-mr (build 32c46643845ea8a705c35d4ec8fc654cc8ff816d)
org.apache.parquet.VersionParser$VersionParseException: Could not parse created_by: parquet-mr (build 32c46643845ea8a705c35d4ec8fc654cc8ff816d) using format: (.*?)\s+version\s*(?:([^(]*?)\s*(?:\(\s*build\s*([^)]*?)\s*\))?)?
	at org.apache.parquet.VersionParser.parse(VersionParser.java:109) ~[parquet-common-1.12.2.jar:1.12.2]
	at org.apache.parquet.CorruptStatistics.shouldIgnoreStatistics(CorruptStatistics.java:72) ~[parquet-column-1.12.2.jar:1.12.2]
	at org.apache.parquet.format.converter.ParquetMetadataConverter.fromParquetStatisticsInternal(ParquetMetadataConverter.java:811) ~[parquet-hadoop-1.12.2.jar:1.12.2]
	at org.apache.parquet.format.converter.ParquetMetadataConverter.fromParquetStatistics(ParquetMetadataConverter.java:831) ~[parquet-hadoop-1.12.2.jar:1.12.2]
	at org.apache.parquet.format.converter.ParquetMetadataConverter.buildColumnChunkMetaData(ParquetMetadataConverter.java:1462) ~[parquet-hadoop-1.12.2.jar:1.12.2]
	at org.apache.parquet.format.converter.ParquetMetadataConverter.fromParquetMetadata(ParquetMetadataConverter.java:1535) ~[parquet-hadoop-1.12.2.jar:1.12.2]
	at org.apache.parquet.format.converter.ParquetMetadataConverter.readParquetMetadata(ParquetMetadataConverter.java:1450) ~[parquet-hadoop-1.12.2.jar:1.12.2]
	at org.apache.parquet.hadoop.ParquetFileReader.readFooter(ParquetFileReader.java:582) ~[parquet-hadoop-1.12.2.jar:1.12.2]
	at org.apache.parquet.hadoop.ParquetFileReader.<init>(ParquetFileReader.java:776) ~[parquet-hadoop-1.12.2.jar:1.12.2]
	at org.apache.spark.sql.execution.datasources.parquet.SpecificParquetRecordReaderBase.initialize(SpecificParquetRecordReaderBase.java:99) ~[spark-sql_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.sql.execution.datasources.parquet.VectorizedParquetRecordReader.initialize(VectorizedParquetRecordReader.java:173) ~[spark-sql_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat.$anonfun$buildReaderWithPartitionValues$1(ParquetFileFormat.scala:343) ~[spark-sql_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:209) ~[spark-sql_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:270) ~[spark-sql_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:116) ~[spark-sql_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.sql.execution.FileSourceScanExec$$anon$1.hasNext(DataSourceScanExec.scala:553) ~[spark-sql_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.columnartorow_nextBatch_0$(Unknown Source) ~[?:?]
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source) ~[?:?]
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43) ~[spark-sql_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:760) ~[spark-sql_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:364) ~[spark-sql_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:890) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:890) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:329) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.scheduler.Task.run(Task.scala:136) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_332]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_332]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_332]
2022-08-15 16:17:16,261 WARN o.a.h.i.c.z.ZlibFactory [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] Failed to load/initialize native-zlib library
2022-08-15 16:20:39,118 WARN o.a.p.CorruptStatistics [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] Ignoring statistics because created_by could not be parsed (see PARQUET-251): parquet-mr (build 32c46643845ea8a705c35d4ec8fc654cc8ff816d)
org.apache.parquet.VersionParser$VersionParseException: Could not parse created_by: parquet-mr (build 32c46643845ea8a705c35d4ec8fc654cc8ff816d) using format: (.*?)\s+version\s*(?:([^(]*?)\s*(?:\(\s*build\s*([^)]*?)\s*\))?)?
	at org.apache.parquet.VersionParser.parse(VersionParser.java:109) ~[parquet-common-1.12.2.jar:1.12.2]
	at org.apache.parquet.CorruptStatistics.shouldIgnoreStatistics(CorruptStatistics.java:72) ~[parquet-column-1.12.2.jar:1.12.2]
	at org.apache.parquet.format.converter.ParquetMetadataConverter.fromParquetStatisticsInternal(ParquetMetadataConverter.java:811) ~[parquet-hadoop-1.12.2.jar:1.12.2]
	at org.apache.parquet.format.converter.ParquetMetadataConverter.fromParquetStatistics(ParquetMetadataConverter.java:831) ~[parquet-hadoop-1.12.2.jar:1.12.2]
	at org.apache.parquet.format.converter.ParquetMetadataConverter.buildColumnChunkMetaData(ParquetMetadataConverter.java:1462) ~[parquet-hadoop-1.12.2.jar:1.12.2]
	at org.apache.parquet.format.converter.ParquetMetadataConverter.fromParquetMetadata(ParquetMetadataConverter.java:1535) ~[parquet-hadoop-1.12.2.jar:1.12.2]
	at org.apache.parquet.format.converter.ParquetMetadataConverter.readParquetMetadata(ParquetMetadataConverter.java:1450) ~[parquet-hadoop-1.12.2.jar:1.12.2]
	at org.apache.parquet.hadoop.ParquetFileReader.readFooter(ParquetFileReader.java:582) ~[parquet-hadoop-1.12.2.jar:1.12.2]
	at org.apache.parquet.hadoop.ParquetFileReader.<init>(ParquetFileReader.java:776) ~[parquet-hadoop-1.12.2.jar:1.12.2]
	at org.apache.spark.sql.execution.datasources.parquet.SpecificParquetRecordReaderBase.initialize(SpecificParquetRecordReaderBase.java:99) ~[spark-sql_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.sql.execution.datasources.parquet.VectorizedParquetRecordReader.initialize(VectorizedParquetRecordReader.java:173) ~[spark-sql_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat.$anonfun$buildReaderWithPartitionValues$1(ParquetFileFormat.scala:343) ~[spark-sql_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:209) ~[spark-sql_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:270) ~[spark-sql_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:116) ~[spark-sql_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.sql.execution.FileSourceScanExec$$anon$1.hasNext(DataSourceScanExec.scala:553) ~[spark-sql_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.columnartorow_nextBatch_0$(Unknown Source) ~[?:?]
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source) ~[?:?]
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43) ~[spark-sql_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:760) ~[spark-sql_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:364) ~[spark-sql_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:890) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:890) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:329) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.scheduler.Task.run(Task.scala:136) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_332]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_332]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_332]
2022-08-15 16:20:39,181 WARN o.a.h.i.c.z.ZlibFactory [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] Failed to load/initialize native-zlib library
2022-08-15 21:02:41,926 WARN o.a.p.CorruptStatistics [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] Ignoring statistics because created_by could not be parsed (see PARQUET-251): parquet-mr (build 32c46643845ea8a705c35d4ec8fc654cc8ff816d)
org.apache.parquet.VersionParser$VersionParseException: Could not parse created_by: parquet-mr (build 32c46643845ea8a705c35d4ec8fc654cc8ff816d) using format: (.*?)\s+version\s*(?:([^(]*?)\s*(?:\(\s*build\s*([^)]*?)\s*\))?)?
	at org.apache.parquet.VersionParser.parse(VersionParser.java:109) ~[parquet-common-1.12.2.jar:1.12.2]
	at org.apache.parquet.CorruptStatistics.shouldIgnoreStatistics(CorruptStatistics.java:72) ~[parquet-column-1.12.2.jar:1.12.2]
	at org.apache.parquet.format.converter.ParquetMetadataConverter.fromParquetStatisticsInternal(ParquetMetadataConverter.java:811) ~[parquet-hadoop-1.12.2.jar:1.12.2]
	at org.apache.parquet.format.converter.ParquetMetadataConverter.fromParquetStatistics(ParquetMetadataConverter.java:831) ~[parquet-hadoop-1.12.2.jar:1.12.2]
	at org.apache.parquet.format.converter.ParquetMetadataConverter.buildColumnChunkMetaData(ParquetMetadataConverter.java:1462) ~[parquet-hadoop-1.12.2.jar:1.12.2]
	at org.apache.parquet.format.converter.ParquetMetadataConverter.fromParquetMetadata(ParquetMetadataConverter.java:1535) ~[parquet-hadoop-1.12.2.jar:1.12.2]
	at org.apache.parquet.format.converter.ParquetMetadataConverter.readParquetMetadata(ParquetMetadataConverter.java:1450) ~[parquet-hadoop-1.12.2.jar:1.12.2]
	at org.apache.parquet.hadoop.ParquetFileReader.readFooter(ParquetFileReader.java:582) ~[parquet-hadoop-1.12.2.jar:1.12.2]
	at org.apache.parquet.hadoop.ParquetFileReader.<init>(ParquetFileReader.java:776) ~[parquet-hadoop-1.12.2.jar:1.12.2]
	at org.apache.spark.sql.execution.datasources.parquet.SpecificParquetRecordReaderBase.initialize(SpecificParquetRecordReaderBase.java:99) ~[spark-sql_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.sql.execution.datasources.parquet.VectorizedParquetRecordReader.initialize(VectorizedParquetRecordReader.java:173) ~[spark-sql_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat.$anonfun$buildReaderWithPartitionValues$1(ParquetFileFormat.scala:343) ~[spark-sql_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:209) ~[spark-sql_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:270) ~[spark-sql_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:116) ~[spark-sql_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.sql.execution.FileSourceScanExec$$anon$1.hasNext(DataSourceScanExec.scala:553) ~[spark-sql_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.columnartorow_nextBatch_0$(Unknown Source) ~[?:?]
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source) ~[?:?]
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43) ~[spark-sql_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:760) ~[spark-sql_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:364) ~[spark-sql_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:890) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:890) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:329) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.scheduler.Task.run(Task.scala:136) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_332]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_332]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_332]
2022-08-15 21:02:42,039 WARN o.a.h.i.c.z.ZlibFactory [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] Failed to load/initialize native-zlib library
2022-08-15 21:13:09,947 WARN o.a.p.CorruptStatistics [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] Ignoring statistics because created_by could not be parsed (see PARQUET-251): parquet-mr (build 32c46643845ea8a705c35d4ec8fc654cc8ff816d)
org.apache.parquet.VersionParser$VersionParseException: Could not parse created_by: parquet-mr (build 32c46643845ea8a705c35d4ec8fc654cc8ff816d) using format: (.*?)\s+version\s*(?:([^(]*?)\s*(?:\(\s*build\s*([^)]*?)\s*\))?)?
	at org.apache.parquet.VersionParser.parse(VersionParser.java:109) ~[parquet-common-1.12.2.jar:1.12.2]
	at org.apache.parquet.CorruptStatistics.shouldIgnoreStatistics(CorruptStatistics.java:72) ~[parquet-column-1.12.2.jar:1.12.2]
	at org.apache.parquet.format.converter.ParquetMetadataConverter.fromParquetStatisticsInternal(ParquetMetadataConverter.java:811) ~[parquet-hadoop-1.12.2.jar:1.12.2]
	at org.apache.parquet.format.converter.ParquetMetadataConverter.fromParquetStatistics(ParquetMetadataConverter.java:831) ~[parquet-hadoop-1.12.2.jar:1.12.2]
	at org.apache.parquet.format.converter.ParquetMetadataConverter.buildColumnChunkMetaData(ParquetMetadataConverter.java:1462) ~[parquet-hadoop-1.12.2.jar:1.12.2]
	at org.apache.parquet.format.converter.ParquetMetadataConverter.fromParquetMetadata(ParquetMetadataConverter.java:1535) ~[parquet-hadoop-1.12.2.jar:1.12.2]
	at org.apache.parquet.format.converter.ParquetMetadataConverter.readParquetMetadata(ParquetMetadataConverter.java:1450) ~[parquet-hadoop-1.12.2.jar:1.12.2]
	at org.apache.parquet.hadoop.ParquetFileReader.readFooter(ParquetFileReader.java:582) ~[parquet-hadoop-1.12.2.jar:1.12.2]
	at org.apache.parquet.hadoop.ParquetFileReader.<init>(ParquetFileReader.java:776) ~[parquet-hadoop-1.12.2.jar:1.12.2]
	at org.apache.spark.sql.execution.datasources.parquet.SpecificParquetRecordReaderBase.initialize(SpecificParquetRecordReaderBase.java:99) ~[spark-sql_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.sql.execution.datasources.parquet.VectorizedParquetRecordReader.initialize(VectorizedParquetRecordReader.java:173) ~[spark-sql_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat.$anonfun$buildReaderWithPartitionValues$1(ParquetFileFormat.scala:343) ~[spark-sql_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:209) ~[spark-sql_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:270) ~[spark-sql_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:116) ~[spark-sql_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.sql.execution.FileSourceScanExec$$anon$1.hasNext(DataSourceScanExec.scala:553) ~[spark-sql_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.columnartorow_nextBatch_0$(Unknown Source) ~[?:?]
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source) ~[?:?]
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43) ~[spark-sql_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:760) ~[spark-sql_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:364) ~[spark-sql_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:890) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:890) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:329) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.scheduler.Task.run(Task.scala:136) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_332]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_332]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_332]
2022-08-15 21:13:10,033 WARN o.a.h.i.c.z.ZlibFactory [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] Failed to load/initialize native-zlib library
2022-08-15 21:14:47,744 WARN o.a.p.CorruptStatistics [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] Ignoring statistics because created_by could not be parsed (see PARQUET-251): parquet-mr (build 32c46643845ea8a705c35d4ec8fc654cc8ff816d)
org.apache.parquet.VersionParser$VersionParseException: Could not parse created_by: parquet-mr (build 32c46643845ea8a705c35d4ec8fc654cc8ff816d) using format: (.*?)\s+version\s*(?:([^(]*?)\s*(?:\(\s*build\s*([^)]*?)\s*\))?)?
	at org.apache.parquet.VersionParser.parse(VersionParser.java:109) ~[parquet-common-1.12.2.jar:1.12.2]
	at org.apache.parquet.CorruptStatistics.shouldIgnoreStatistics(CorruptStatistics.java:72) ~[parquet-column-1.12.2.jar:1.12.2]
	at org.apache.parquet.format.converter.ParquetMetadataConverter.fromParquetStatisticsInternal(ParquetMetadataConverter.java:811) ~[parquet-hadoop-1.12.2.jar:1.12.2]
	at org.apache.parquet.format.converter.ParquetMetadataConverter.fromParquetStatistics(ParquetMetadataConverter.java:831) ~[parquet-hadoop-1.12.2.jar:1.12.2]
	at org.apache.parquet.format.converter.ParquetMetadataConverter.buildColumnChunkMetaData(ParquetMetadataConverter.java:1462) ~[parquet-hadoop-1.12.2.jar:1.12.2]
	at org.apache.parquet.format.converter.ParquetMetadataConverter.fromParquetMetadata(ParquetMetadataConverter.java:1535) ~[parquet-hadoop-1.12.2.jar:1.12.2]
	at org.apache.parquet.format.converter.ParquetMetadataConverter.readParquetMetadata(ParquetMetadataConverter.java:1450) ~[parquet-hadoop-1.12.2.jar:1.12.2]
	at org.apache.parquet.hadoop.ParquetFileReader.readFooter(ParquetFileReader.java:582) ~[parquet-hadoop-1.12.2.jar:1.12.2]
	at org.apache.parquet.hadoop.ParquetFileReader.<init>(ParquetFileReader.java:776) ~[parquet-hadoop-1.12.2.jar:1.12.2]
	at org.apache.spark.sql.execution.datasources.parquet.SpecificParquetRecordReaderBase.initialize(SpecificParquetRecordReaderBase.java:99) ~[spark-sql_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.sql.execution.datasources.parquet.VectorizedParquetRecordReader.initialize(VectorizedParquetRecordReader.java:173) ~[spark-sql_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat.$anonfun$buildReaderWithPartitionValues$1(ParquetFileFormat.scala:343) ~[spark-sql_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:209) ~[spark-sql_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:270) ~[spark-sql_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:116) ~[spark-sql_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.sql.execution.FileSourceScanExec$$anon$1.hasNext(DataSourceScanExec.scala:553) ~[spark-sql_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.columnartorow_nextBatch_0$(Unknown Source) ~[?:?]
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source) ~[?:?]
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43) ~[spark-sql_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:760) ~[spark-sql_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:364) ~[spark-sql_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:890) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:890) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:329) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.scheduler.Task.run(Task.scala:136) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_332]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_332]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_332]
2022-08-15 21:14:47,852 WARN o.a.h.i.c.z.ZlibFactory [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] Failed to load/initialize native-zlib library
2022-08-16 20:57:08,825 WARN o.a.s.e.ProcfsMetricsGetter [executor-heartbeater] Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
2022-08-16 21:36:52,436 WARN o.a.s.e.ProcfsMetricsGetter [executor-heartbeater] Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
2022-08-18 14:03:28,319 WARN o.a.s.e.ProcfsMetricsGetter [driver-heartbeater] Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
2022-08-18 14:03:28,695 ERROR o.a.s.ContextCleaner [Spark Context Cleaner] Error cleaning shuffle 5
java.lang.NullPointerException: null
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1(MapOutputTracker.scala:882) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1$adapted(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.MapOutputTrackerMaster.unregisterShuffle(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner.doCleanupShuffle(ContextCleaner.scala:241) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner.$anonfun$keepCleaning$3(ContextCleaner.scala:202) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner.$anonfun$keepCleaning$3$adapted(ContextCleaner.scala:195) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.ContextCleaner.$anonfun$keepCleaning$1(ContextCleaner.scala:195) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1446) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner.org$apache$spark$ContextCleaner$$keepCleaning(ContextCleaner.scala:189) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner$$anon$1.run(ContextCleaner.scala:79) ~[spark-core_2.13-3.3.0.jar:3.3.0]
2022-08-18 14:03:32,891 ERROR o.a.s.ContextCleaner [Spark Context Cleaner] Error cleaning shuffle 19
java.lang.NullPointerException: null
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1(MapOutputTracker.scala:882) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1$adapted(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.MapOutputTrackerMaster.unregisterShuffle(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner.doCleanupShuffle(ContextCleaner.scala:241) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner.$anonfun$keepCleaning$3(ContextCleaner.scala:202) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner.$anonfun$keepCleaning$3$adapted(ContextCleaner.scala:195) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.ContextCleaner.$anonfun$keepCleaning$1(ContextCleaner.scala:195) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1446) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner.org$apache$spark$ContextCleaner$$keepCleaning(ContextCleaner.scala:189) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner$$anon$1.run(ContextCleaner.scala:79) ~[spark-core_2.13-3.3.0.jar:3.3.0]
2022-08-18 14:03:32,899 ERROR o.a.s.s.BlockManagerStorageEndpoint [block-manager-storage-async-thread-pool-84] Error in removing shuffle 18
java.lang.NullPointerException: null
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1(MapOutputTracker.scala:882) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1$adapted(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.MapOutputTrackerMaster.unregisterShuffle(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.storage.BlockManagerStorageEndpoint$$anonfun$receiveAndReply$1.$anonfun$applyOrElse$3(BlockManagerStorageEndpoint.scala:59) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.scala:17) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.storage.BlockManagerStorageEndpoint.$anonfun$doAsync$1(BlockManagerStorageEndpoint.scala:89) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:678) ~[scala-library-2.13.8.jar:?]
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467) ~[scala-library-2.13.8.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_332]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_332]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_332]
2022-08-18 14:03:32,899 WARN o.a.s.s.BlockManagerMaster [block-manager-ask-thread-pool-23] Failed to remove shuffle 18 - null
java.lang.NullPointerException: null
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1(MapOutputTracker.scala:882) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1$adapted(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.MapOutputTrackerMaster.unregisterShuffle(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.storage.BlockManagerStorageEndpoint$$anonfun$receiveAndReply$1.$anonfun$applyOrElse$3(BlockManagerStorageEndpoint.scala:59) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.scala:17) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.storage.BlockManagerStorageEndpoint.$anonfun$doAsync$1(BlockManagerStorageEndpoint.scala:89) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:678) ~[scala-library-2.13.8.jar:?]
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467) ~[scala-library-2.13.8.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_332]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_332]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_332]
2022-08-18 14:03:34,172 ERROR o.a.s.ContextCleaner [Spark Context Cleaner] Error cleaning shuffle 23
java.lang.NullPointerException: null
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1(MapOutputTracker.scala:882) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1$adapted(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.MapOutputTrackerMaster.unregisterShuffle(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner.doCleanupShuffle(ContextCleaner.scala:241) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner.$anonfun$keepCleaning$3(ContextCleaner.scala:202) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner.$anonfun$keepCleaning$3$adapted(ContextCleaner.scala:195) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.ContextCleaner.$anonfun$keepCleaning$1(ContextCleaner.scala:195) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1446) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner.org$apache$spark$ContextCleaner$$keepCleaning(ContextCleaner.scala:189) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner$$anon$1.run(ContextCleaner.scala:79) ~[spark-core_2.13-3.3.0.jar:3.3.0]
2022-08-18 14:03:34,172 ERROR o.a.s.s.BlockManagerStorageEndpoint [block-manager-storage-async-thread-pool-83] Error in removing shuffle 22
java.lang.NullPointerException: null
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1(MapOutputTracker.scala:882) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1$adapted(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.MapOutputTrackerMaster.unregisterShuffle(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.storage.BlockManagerStorageEndpoint$$anonfun$receiveAndReply$1.$anonfun$applyOrElse$3(BlockManagerStorageEndpoint.scala:59) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.scala:17) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.storage.BlockManagerStorageEndpoint.$anonfun$doAsync$1(BlockManagerStorageEndpoint.scala:89) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:678) ~[scala-library-2.13.8.jar:?]
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467) ~[scala-library-2.13.8.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_332]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_332]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_332]
2022-08-18 14:03:34,172 WARN o.a.s.s.BlockManagerMaster [block-manager-ask-thread-pool-57] Failed to remove shuffle 22 - null
java.lang.NullPointerException: null
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1(MapOutputTracker.scala:882) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1$adapted(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.MapOutputTrackerMaster.unregisterShuffle(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.storage.BlockManagerStorageEndpoint$$anonfun$receiveAndReply$1.$anonfun$applyOrElse$3(BlockManagerStorageEndpoint.scala:59) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.scala:17) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.storage.BlockManagerStorageEndpoint.$anonfun$doAsync$1(BlockManagerStorageEndpoint.scala:89) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:678) ~[scala-library-2.13.8.jar:?]
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467) ~[scala-library-2.13.8.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_332]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_332]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_332]
2022-08-18 14:03:35,571 ERROR o.a.s.s.BlockManagerStorageEndpoint [block-manager-storage-async-thread-pool-21] Error in removing shuffle 27
java.lang.NullPointerException: null
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1(MapOutputTracker.scala:882) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1$adapted(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.MapOutputTrackerMaster.unregisterShuffle(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.storage.BlockManagerStorageEndpoint$$anonfun$receiveAndReply$1.$anonfun$applyOrElse$3(BlockManagerStorageEndpoint.scala:59) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.scala:17) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.storage.BlockManagerStorageEndpoint.$anonfun$doAsync$1(BlockManagerStorageEndpoint.scala:89) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:678) ~[scala-library-2.13.8.jar:?]
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467) ~[scala-library-2.13.8.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_332]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_332]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_332]
2022-08-18 14:03:35,571 WARN o.a.s.s.BlockManagerMaster [block-manager-ask-thread-pool-51] Failed to remove shuffle 27 - null
java.lang.NullPointerException: null
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1(MapOutputTracker.scala:882) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1$adapted(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.MapOutputTrackerMaster.unregisterShuffle(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.storage.BlockManagerStorageEndpoint$$anonfun$receiveAndReply$1.$anonfun$applyOrElse$3(BlockManagerStorageEndpoint.scala:59) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.scala:17) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.storage.BlockManagerStorageEndpoint.$anonfun$doAsync$1(BlockManagerStorageEndpoint.scala:89) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:678) ~[scala-library-2.13.8.jar:?]
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467) ~[scala-library-2.13.8.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_332]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_332]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_332]
2022-08-18 14:03:35,571 ERROR o.a.s.s.BlockManagerStorageEndpoint [block-manager-storage-async-thread-pool-74] Error in removing shuffle 24
java.lang.NullPointerException: null
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1(MapOutputTracker.scala:882) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1$adapted(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.MapOutputTrackerMaster.unregisterShuffle(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.storage.BlockManagerStorageEndpoint$$anonfun$receiveAndReply$1.$anonfun$applyOrElse$3(BlockManagerStorageEndpoint.scala:59) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.scala:17) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.storage.BlockManagerStorageEndpoint.$anonfun$doAsync$1(BlockManagerStorageEndpoint.scala:89) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:678) ~[scala-library-2.13.8.jar:?]
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467) ~[scala-library-2.13.8.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_332]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_332]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_332]
2022-08-18 14:03:35,571 WARN o.a.s.s.BlockManagerMaster [block-manager-ask-thread-pool-86] Failed to remove shuffle 24 - null
java.lang.NullPointerException: null
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1(MapOutputTracker.scala:882) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1$adapted(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.MapOutputTrackerMaster.unregisterShuffle(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.storage.BlockManagerStorageEndpoint$$anonfun$receiveAndReply$1.$anonfun$applyOrElse$3(BlockManagerStorageEndpoint.scala:59) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.scala:17) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.storage.BlockManagerStorageEndpoint.$anonfun$doAsync$1(BlockManagerStorageEndpoint.scala:89) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:678) ~[scala-library-2.13.8.jar:?]
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467) ~[scala-library-2.13.8.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_332]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_332]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_332]
2022-08-18 14:03:36,708 ERROR o.a.s.s.BlockManagerStorageEndpoint [block-manager-storage-async-thread-pool-20] Error in removing shuffle 31
java.lang.NullPointerException: null
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1(MapOutputTracker.scala:882) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1$adapted(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.MapOutputTrackerMaster.unregisterShuffle(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.storage.BlockManagerStorageEndpoint$$anonfun$receiveAndReply$1.$anonfun$applyOrElse$3(BlockManagerStorageEndpoint.scala:59) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.scala:17) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.storage.BlockManagerStorageEndpoint.$anonfun$doAsync$1(BlockManagerStorageEndpoint.scala:89) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:678) ~[scala-library-2.13.8.jar:?]
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467) ~[scala-library-2.13.8.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_332]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_332]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_332]
2022-08-18 14:03:36,708 WARN o.a.s.s.BlockManagerMaster [block-manager-ask-thread-pool-10] Failed to remove shuffle 31 - null
java.lang.NullPointerException: null
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1(MapOutputTracker.scala:882) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1$adapted(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.MapOutputTrackerMaster.unregisterShuffle(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.storage.BlockManagerStorageEndpoint$$anonfun$receiveAndReply$1.$anonfun$applyOrElse$3(BlockManagerStorageEndpoint.scala:59) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.scala:17) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.storage.BlockManagerStorageEndpoint.$anonfun$doAsync$1(BlockManagerStorageEndpoint.scala:89) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:678) ~[scala-library-2.13.8.jar:?]
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467) ~[scala-library-2.13.8.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_332]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_332]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_332]
2022-08-18 14:03:36,716 ERROR o.a.s.s.BlockManagerStorageEndpoint [block-manager-storage-async-thread-pool-50] Error in removing shuffle 28
java.lang.NullPointerException: null
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1(MapOutputTracker.scala:882) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1$adapted(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.MapOutputTrackerMaster.unregisterShuffle(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.storage.BlockManagerStorageEndpoint$$anonfun$receiveAndReply$1.$anonfun$applyOrElse$3(BlockManagerStorageEndpoint.scala:59) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.scala:17) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.storage.BlockManagerStorageEndpoint.$anonfun$doAsync$1(BlockManagerStorageEndpoint.scala:89) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:678) ~[scala-library-2.13.8.jar:?]
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467) ~[scala-library-2.13.8.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_332]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_332]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_332]
2022-08-18 14:03:36,716 WARN o.a.s.s.BlockManagerMaster [block-manager-ask-thread-pool-35] Failed to remove shuffle 28 - null
java.lang.NullPointerException: null
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1(MapOutputTracker.scala:882) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1$adapted(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.MapOutputTrackerMaster.unregisterShuffle(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.storage.BlockManagerStorageEndpoint$$anonfun$receiveAndReply$1.$anonfun$applyOrElse$3(BlockManagerStorageEndpoint.scala:59) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.scala:17) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.storage.BlockManagerStorageEndpoint.$anonfun$doAsync$1(BlockManagerStorageEndpoint.scala:89) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:678) ~[scala-library-2.13.8.jar:?]
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467) ~[scala-library-2.13.8.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_332]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_332]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_332]
2022-08-18 14:03:36,724 ERROR o.a.s.s.BlockManagerStorageEndpoint [block-manager-storage-async-thread-pool-7] Error in removing shuffle 29
java.lang.NullPointerException: null
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1(MapOutputTracker.scala:882) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1$adapted(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.MapOutputTrackerMaster.unregisterShuffle(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.storage.BlockManagerStorageEndpoint$$anonfun$receiveAndReply$1.$anonfun$applyOrElse$3(BlockManagerStorageEndpoint.scala:59) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.scala:17) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.storage.BlockManagerStorageEndpoint.$anonfun$doAsync$1(BlockManagerStorageEndpoint.scala:89) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:678) ~[scala-library-2.13.8.jar:?]
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467) ~[scala-library-2.13.8.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_332]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_332]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_332]
2022-08-18 14:03:36,724 WARN o.a.s.s.BlockManagerMaster [block-manager-ask-thread-pool-76] Failed to remove shuffle 29 - null
java.lang.NullPointerException: null
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1(MapOutputTracker.scala:882) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1$adapted(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.MapOutputTrackerMaster.unregisterShuffle(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.storage.BlockManagerStorageEndpoint$$anonfun$receiveAndReply$1.$anonfun$applyOrElse$3(BlockManagerStorageEndpoint.scala:59) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.scala:17) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.storage.BlockManagerStorageEndpoint.$anonfun$doAsync$1(BlockManagerStorageEndpoint.scala:89) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:678) ~[scala-library-2.13.8.jar:?]
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467) ~[scala-library-2.13.8.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_332]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_332]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_332]
2022-08-18 14:03:37,757 ERROR o.a.s.ContextCleaner [Spark Context Cleaner] Error cleaning shuffle 43
java.lang.NullPointerException: null
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1(MapOutputTracker.scala:882) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1$adapted(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.MapOutputTrackerMaster.unregisterShuffle(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner.doCleanupShuffle(ContextCleaner.scala:241) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner.$anonfun$keepCleaning$3(ContextCleaner.scala:202) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner.$anonfun$keepCleaning$3$adapted(ContextCleaner.scala:195) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.ContextCleaner.$anonfun$keepCleaning$1(ContextCleaner.scala:195) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1446) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner.org$apache$spark$ContextCleaner$$keepCleaning(ContextCleaner.scala:189) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner$$anon$1.run(ContextCleaner.scala:79) ~[spark-core_2.13-3.3.0.jar:3.3.0]
2022-08-18 14:03:37,757 ERROR o.a.s.ContextCleaner [Spark Context Cleaner] Error cleaning shuffle 41
java.lang.NullPointerException: null
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1(MapOutputTracker.scala:882) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1$adapted(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.MapOutputTrackerMaster.unregisterShuffle(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner.doCleanupShuffle(ContextCleaner.scala:241) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner.$anonfun$keepCleaning$3(ContextCleaner.scala:202) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner.$anonfun$keepCleaning$3$adapted(ContextCleaner.scala:195) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.ContextCleaner.$anonfun$keepCleaning$1(ContextCleaner.scala:195) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1446) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner.org$apache$spark$ContextCleaner$$keepCleaning(ContextCleaner.scala:189) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner$$anon$1.run(ContextCleaner.scala:79) ~[spark-core_2.13-3.3.0.jar:3.3.0]
2022-08-18 14:03:39,006 ERROR o.a.s.s.BlockManagerStorageEndpoint [block-manager-storage-async-thread-pool-7] Error in removing shuffle 51
java.lang.NullPointerException: null
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1(MapOutputTracker.scala:882) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1$adapted(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.MapOutputTrackerMaster.unregisterShuffle(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.storage.BlockManagerStorageEndpoint$$anonfun$receiveAndReply$1.$anonfun$applyOrElse$3(BlockManagerStorageEndpoint.scala:59) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.scala:17) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.storage.BlockManagerStorageEndpoint.$anonfun$doAsync$1(BlockManagerStorageEndpoint.scala:89) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:678) ~[scala-library-2.13.8.jar:?]
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467) ~[scala-library-2.13.8.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_332]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_332]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_332]
2022-08-18 14:03:39,006 WARN o.a.s.s.BlockManagerMaster [block-manager-ask-thread-pool-44] Failed to remove shuffle 51 - null
java.lang.NullPointerException: null
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1(MapOutputTracker.scala:882) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1$adapted(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.MapOutputTrackerMaster.unregisterShuffle(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.storage.BlockManagerStorageEndpoint$$anonfun$receiveAndReply$1.$anonfun$applyOrElse$3(BlockManagerStorageEndpoint.scala:59) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.scala:17) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.storage.BlockManagerStorageEndpoint.$anonfun$doAsync$1(BlockManagerStorageEndpoint.scala:89) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:678) ~[scala-library-2.13.8.jar:?]
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467) ~[scala-library-2.13.8.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_332]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_332]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_332]
2022-08-18 14:10:52,741 WARN o.a.s.e.ProcfsMetricsGetter [executor-heartbeater] Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
2022-08-18 14:10:59,091 ERROR o.a.s.ContextCleaner [Spark Context Cleaner] Error cleaning shuffle 22
java.lang.NullPointerException: null
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1(MapOutputTracker.scala:882) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1$adapted(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.MapOutputTrackerMaster.unregisterShuffle(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner.doCleanupShuffle(ContextCleaner.scala:241) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner.$anonfun$keepCleaning$3(ContextCleaner.scala:202) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner.$anonfun$keepCleaning$3$adapted(ContextCleaner.scala:195) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.ContextCleaner.$anonfun$keepCleaning$1(ContextCleaner.scala:195) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1446) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner.org$apache$spark$ContextCleaner$$keepCleaning(ContextCleaner.scala:189) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner$$anon$1.run(ContextCleaner.scala:79) ~[spark-core_2.13-3.3.0.jar:3.3.0]
2022-08-18 14:10:59,091 ERROR o.a.s.s.BlockManagerStorageEndpoint [block-manager-storage-async-thread-pool-90] Error in removing shuffle 16
java.lang.NullPointerException: null
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1(MapOutputTracker.scala:882) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1$adapted(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.MapOutputTrackerMaster.unregisterShuffle(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.storage.BlockManagerStorageEndpoint$$anonfun$receiveAndReply$1.$anonfun$applyOrElse$3(BlockManagerStorageEndpoint.scala:59) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.scala:17) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.storage.BlockManagerStorageEndpoint.$anonfun$doAsync$1(BlockManagerStorageEndpoint.scala:89) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:678) ~[scala-library-2.13.8.jar:?]
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467) ~[scala-library-2.13.8.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_332]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_332]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_332]
2022-08-18 14:10:59,109 WARN o.a.s.s.BlockManagerMaster [block-manager-ask-thread-pool-32] Failed to remove shuffle 16 - null
java.lang.NullPointerException: null
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1(MapOutputTracker.scala:882) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1$adapted(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.MapOutputTrackerMaster.unregisterShuffle(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.storage.BlockManagerStorageEndpoint$$anonfun$receiveAndReply$1.$anonfun$applyOrElse$3(BlockManagerStorageEndpoint.scala:59) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.scala:17) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.storage.BlockManagerStorageEndpoint.$anonfun$doAsync$1(BlockManagerStorageEndpoint.scala:89) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:678) ~[scala-library-2.13.8.jar:?]
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467) ~[scala-library-2.13.8.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_332]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_332]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_332]
2022-08-18 14:10:59,114 ERROR o.a.s.ContextCleaner [Spark Context Cleaner] Error cleaning shuffle 18
java.lang.NullPointerException: null
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1(MapOutputTracker.scala:882) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1$adapted(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.MapOutputTrackerMaster.unregisterShuffle(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner.doCleanupShuffle(ContextCleaner.scala:241) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner.$anonfun$keepCleaning$3(ContextCleaner.scala:202) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner.$anonfun$keepCleaning$3$adapted(ContextCleaner.scala:195) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.ContextCleaner.$anonfun$keepCleaning$1(ContextCleaner.scala:195) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1446) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner.org$apache$spark$ContextCleaner$$keepCleaning(ContextCleaner.scala:189) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner$$anon$1.run(ContextCleaner.scala:79) ~[spark-core_2.13-3.3.0.jar:3.3.0]
2022-08-18 14:10:59,119 ERROR o.a.s.s.BlockManagerStorageEndpoint [block-manager-storage-async-thread-pool-49] Error in removing shuffle 20
java.lang.NullPointerException: null
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1(MapOutputTracker.scala:882) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1$adapted(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.MapOutputTrackerMaster.unregisterShuffle(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.storage.BlockManagerStorageEndpoint$$anonfun$receiveAndReply$1.$anonfun$applyOrElse$3(BlockManagerStorageEndpoint.scala:59) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.scala:17) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.storage.BlockManagerStorageEndpoint.$anonfun$doAsync$1(BlockManagerStorageEndpoint.scala:89) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:678) ~[scala-library-2.13.8.jar:?]
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467) ~[scala-library-2.13.8.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_332]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_332]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_332]
2022-08-18 14:10:59,119 WARN o.a.s.s.BlockManagerMaster [block-manager-ask-thread-pool-64] Failed to remove shuffle 20 - null
java.lang.NullPointerException: null
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1(MapOutputTracker.scala:882) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1$adapted(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.MapOutputTrackerMaster.unregisterShuffle(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.storage.BlockManagerStorageEndpoint$$anonfun$receiveAndReply$1.$anonfun$applyOrElse$3(BlockManagerStorageEndpoint.scala:59) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.scala:17) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.storage.BlockManagerStorageEndpoint.$anonfun$doAsync$1(BlockManagerStorageEndpoint.scala:89) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:678) ~[scala-library-2.13.8.jar:?]
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467) ~[scala-library-2.13.8.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_332]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_332]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_332]
2022-08-18 14:10:59,122 ERROR o.a.s.s.BlockManagerStorageEndpoint [block-manager-storage-async-thread-pool-56] Error in removing shuffle 17
java.lang.NullPointerException: null
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1(MapOutputTracker.scala:882) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1$adapted(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.MapOutputTrackerMaster.unregisterShuffle(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.storage.BlockManagerStorageEndpoint$$anonfun$receiveAndReply$1.$anonfun$applyOrElse$3(BlockManagerStorageEndpoint.scala:59) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.scala:17) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.storage.BlockManagerStorageEndpoint.$anonfun$doAsync$1(BlockManagerStorageEndpoint.scala:89) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:678) ~[scala-library-2.13.8.jar:?]
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467) ~[scala-library-2.13.8.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_332]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_332]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_332]
2022-08-18 14:10:59,122 WARN o.a.s.s.BlockManagerMaster [block-manager-ask-thread-pool-70] Failed to remove shuffle 17 - null
java.lang.NullPointerException: null
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1(MapOutputTracker.scala:882) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1$adapted(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.MapOutputTrackerMaster.unregisterShuffle(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.storage.BlockManagerStorageEndpoint$$anonfun$receiveAndReply$1.$anonfun$applyOrElse$3(BlockManagerStorageEndpoint.scala:59) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.scala:17) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.storage.BlockManagerStorageEndpoint.$anonfun$doAsync$1(BlockManagerStorageEndpoint.scala:89) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:678) ~[scala-library-2.13.8.jar:?]
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467) ~[scala-library-2.13.8.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_332]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_332]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_332]
2022-08-18 14:11:00,163 ERROR o.a.s.ContextCleaner [Spark Context Cleaner] Error cleaning shuffle 24
java.lang.NullPointerException: null
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1(MapOutputTracker.scala:882) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1$adapted(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.MapOutputTrackerMaster.unregisterShuffle(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner.doCleanupShuffle(ContextCleaner.scala:241) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner.$anonfun$keepCleaning$3(ContextCleaner.scala:202) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner.$anonfun$keepCleaning$3$adapted(ContextCleaner.scala:195) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.ContextCleaner.$anonfun$keepCleaning$1(ContextCleaner.scala:195) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1446) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner.org$apache$spark$ContextCleaner$$keepCleaning(ContextCleaner.scala:189) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner$$anon$1.run(ContextCleaner.scala:79) ~[spark-core_2.13-3.3.0.jar:3.3.0]
2022-08-18 14:11:02,019 ERROR o.a.s.s.BlockManagerStorageEndpoint [block-manager-storage-async-thread-pool-33] Error in removing shuffle 33
java.lang.NullPointerException: null
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1(MapOutputTracker.scala:882) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1$adapted(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.MapOutputTrackerMaster.unregisterShuffle(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.storage.BlockManagerStorageEndpoint$$anonfun$receiveAndReply$1.$anonfun$applyOrElse$3(BlockManagerStorageEndpoint.scala:59) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.scala:17) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.storage.BlockManagerStorageEndpoint.$anonfun$doAsync$1(BlockManagerStorageEndpoint.scala:89) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:678) ~[scala-library-2.13.8.jar:?]
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467) ~[scala-library-2.13.8.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_332]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_332]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_332]
2022-08-18 14:11:02,021 WARN o.a.s.s.BlockManagerMaster [block-manager-ask-thread-pool-54] Failed to remove shuffle 33 - null
java.lang.NullPointerException: null
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1(MapOutputTracker.scala:882) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1$adapted(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.MapOutputTrackerMaster.unregisterShuffle(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.storage.BlockManagerStorageEndpoint$$anonfun$receiveAndReply$1.$anonfun$applyOrElse$3(BlockManagerStorageEndpoint.scala:59) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.scala:17) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.storage.BlockManagerStorageEndpoint.$anonfun$doAsync$1(BlockManagerStorageEndpoint.scala:89) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:678) ~[scala-library-2.13.8.jar:?]
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467) ~[scala-library-2.13.8.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_332]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_332]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_332]
2022-08-18 14:11:04,719 ERROR o.a.s.ContextCleaner [Spark Context Cleaner] Error cleaning shuffle 39
java.lang.NullPointerException: null
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1(MapOutputTracker.scala:882) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1$adapted(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.MapOutputTrackerMaster.unregisterShuffle(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner.doCleanupShuffle(ContextCleaner.scala:241) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner.$anonfun$keepCleaning$3(ContextCleaner.scala:202) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner.$anonfun$keepCleaning$3$adapted(ContextCleaner.scala:195) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.ContextCleaner.$anonfun$keepCleaning$1(ContextCleaner.scala:195) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1446) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner.org$apache$spark$ContextCleaner$$keepCleaning(ContextCleaner.scala:189) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner$$anon$1.run(ContextCleaner.scala:79) ~[spark-core_2.13-3.3.0.jar:3.3.0]
2022-08-18 14:11:04,723 ERROR o.a.s.s.BlockManagerStorageEndpoint [block-manager-storage-async-thread-pool-41] Error in removing shuffle 40
java.lang.NullPointerException: null
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1(MapOutputTracker.scala:882) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1$adapted(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.MapOutputTrackerMaster.unregisterShuffle(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.storage.BlockManagerStorageEndpoint$$anonfun$receiveAndReply$1.$anonfun$applyOrElse$3(BlockManagerStorageEndpoint.scala:59) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.scala:17) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.storage.BlockManagerStorageEndpoint.$anonfun$doAsync$1(BlockManagerStorageEndpoint.scala:89) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:678) ~[scala-library-2.13.8.jar:?]
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467) ~[scala-library-2.13.8.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_332]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_332]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_332]
2022-08-18 14:11:04,723 WARN o.a.s.s.BlockManagerMaster [block-manager-ask-thread-pool-3] Failed to remove shuffle 40 - null
java.lang.NullPointerException: null
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1(MapOutputTracker.scala:882) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1$adapted(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.MapOutputTrackerMaster.unregisterShuffle(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.storage.BlockManagerStorageEndpoint$$anonfun$receiveAndReply$1.$anonfun$applyOrElse$3(BlockManagerStorageEndpoint.scala:59) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.scala:17) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.storage.BlockManagerStorageEndpoint.$anonfun$doAsync$1(BlockManagerStorageEndpoint.scala:89) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:678) ~[scala-library-2.13.8.jar:?]
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467) ~[scala-library-2.13.8.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_332]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_332]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_332]
2022-08-18 14:11:04,729 ERROR o.a.s.s.BlockManagerStorageEndpoint [block-manager-storage-async-thread-pool-10] Error in removing shuffle 43
java.lang.NullPointerException: null
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1(MapOutputTracker.scala:882) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1$adapted(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.MapOutputTrackerMaster.unregisterShuffle(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.storage.BlockManagerStorageEndpoint$$anonfun$receiveAndReply$1.$anonfun$applyOrElse$3(BlockManagerStorageEndpoint.scala:59) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.scala:17) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.storage.BlockManagerStorageEndpoint.$anonfun$doAsync$1(BlockManagerStorageEndpoint.scala:89) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:678) ~[scala-library-2.13.8.jar:?]
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467) ~[scala-library-2.13.8.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_332]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_332]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_332]
2022-08-18 14:11:04,729 WARN o.a.s.s.BlockManagerMaster [block-manager-ask-thread-pool-40] Failed to remove shuffle 43 - null
java.lang.NullPointerException: null
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1(MapOutputTracker.scala:882) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1$adapted(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.MapOutputTrackerMaster.unregisterShuffle(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.storage.BlockManagerStorageEndpoint$$anonfun$receiveAndReply$1.$anonfun$applyOrElse$3(BlockManagerStorageEndpoint.scala:59) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.scala:17) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.storage.BlockManagerStorageEndpoint.$anonfun$doAsync$1(BlockManagerStorageEndpoint.scala:89) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:678) ~[scala-library-2.13.8.jar:?]
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467) ~[scala-library-2.13.8.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_332]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_332]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_332]
2022-08-18 14:11:05,979 ERROR o.a.s.s.BlockManagerStorageEndpoint [block-manager-storage-async-thread-pool-68] Error in removing shuffle 50
java.lang.NullPointerException: null
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1(MapOutputTracker.scala:882) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1$adapted(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.MapOutputTrackerMaster.unregisterShuffle(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.storage.BlockManagerStorageEndpoint$$anonfun$receiveAndReply$1.$anonfun$applyOrElse$3(BlockManagerStorageEndpoint.scala:59) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.scala:17) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.storage.BlockManagerStorageEndpoint.$anonfun$doAsync$1(BlockManagerStorageEndpoint.scala:89) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:678) ~[scala-library-2.13.8.jar:?]
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467) ~[scala-library-2.13.8.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_332]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_332]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_332]
2022-08-18 14:11:05,979 WARN o.a.s.s.BlockManagerMaster [block-manager-ask-thread-pool-59] Failed to remove shuffle 50 - null
java.lang.NullPointerException: null
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1(MapOutputTracker.scala:882) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1$adapted(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.MapOutputTrackerMaster.unregisterShuffle(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.storage.BlockManagerStorageEndpoint$$anonfun$receiveAndReply$1.$anonfun$applyOrElse$3(BlockManagerStorageEndpoint.scala:59) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.scala:17) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.storage.BlockManagerStorageEndpoint.$anonfun$doAsync$1(BlockManagerStorageEndpoint.scala:89) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:678) ~[scala-library-2.13.8.jar:?]
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467) ~[scala-library-2.13.8.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_332]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_332]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_332]
2022-08-18 14:11:05,989 ERROR o.a.s.ContextCleaner [Spark Context Cleaner] Error cleaning shuffle 47
java.lang.NullPointerException: null
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1(MapOutputTracker.scala:882) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1$adapted(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.MapOutputTrackerMaster.unregisterShuffle(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner.doCleanupShuffle(ContextCleaner.scala:241) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner.$anonfun$keepCleaning$3(ContextCleaner.scala:202) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner.$anonfun$keepCleaning$3$adapted(ContextCleaner.scala:195) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.ContextCleaner.$anonfun$keepCleaning$1(ContextCleaner.scala:195) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1446) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner.org$apache$spark$ContextCleaner$$keepCleaning(ContextCleaner.scala:189) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.ContextCleaner$$anon$1.run(ContextCleaner.scala:79) ~[spark-core_2.13-3.3.0.jar:3.3.0]
2022-08-18 14:11:05,989 ERROR o.a.s.s.BlockManagerStorageEndpoint [block-manager-storage-async-thread-pool-44] Error in removing shuffle 44
java.lang.NullPointerException: null
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1(MapOutputTracker.scala:882) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1$adapted(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.MapOutputTrackerMaster.unregisterShuffle(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.storage.BlockManagerStorageEndpoint$$anonfun$receiveAndReply$1.$anonfun$applyOrElse$3(BlockManagerStorageEndpoint.scala:59) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.scala:17) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.storage.BlockManagerStorageEndpoint.$anonfun$doAsync$1(BlockManagerStorageEndpoint.scala:89) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:678) ~[scala-library-2.13.8.jar:?]
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467) ~[scala-library-2.13.8.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_332]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_332]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_332]
2022-08-18 14:11:05,989 WARN o.a.s.s.BlockManagerMaster [block-manager-ask-thread-pool-99] Failed to remove shuffle 44 - null
java.lang.NullPointerException: null
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1(MapOutputTracker.scala:882) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1$adapted(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.MapOutputTrackerMaster.unregisterShuffle(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.storage.BlockManagerStorageEndpoint$$anonfun$receiveAndReply$1.$anonfun$applyOrElse$3(BlockManagerStorageEndpoint.scala:59) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.scala:17) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.storage.BlockManagerStorageEndpoint.$anonfun$doAsync$1(BlockManagerStorageEndpoint.scala:89) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:678) ~[scala-library-2.13.8.jar:?]
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467) ~[scala-library-2.13.8.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_332]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_332]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_332]
2022-08-18 14:11:08,559 ERROR o.a.s.s.BlockManagerStorageEndpoint [block-manager-storage-async-thread-pool-81] Error in removing shuffle 55
java.lang.NullPointerException: null
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1(MapOutputTracker.scala:882) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1$adapted(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.MapOutputTrackerMaster.unregisterShuffle(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.storage.BlockManagerStorageEndpoint$$anonfun$receiveAndReply$1.$anonfun$applyOrElse$3(BlockManagerStorageEndpoint.scala:59) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.scala:17) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.storage.BlockManagerStorageEndpoint.$anonfun$doAsync$1(BlockManagerStorageEndpoint.scala:89) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:678) ~[scala-library-2.13.8.jar:?]
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467) ~[scala-library-2.13.8.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_332]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_332]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_332]
2022-08-18 14:11:08,559 WARN o.a.s.s.BlockManagerMaster [block-manager-ask-thread-pool-94] Failed to remove shuffle 55 - null
java.lang.NullPointerException: null
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1(MapOutputTracker.scala:882) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.MapOutputTrackerMaster.$anonfun$unregisterShuffle$1$adapted(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.MapOutputTrackerMaster.unregisterShuffle(MapOutputTracker.scala:881) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at org.apache.spark.storage.BlockManagerStorageEndpoint$$anonfun$receiveAndReply$1.$anonfun$applyOrElse$3(BlockManagerStorageEndpoint.scala:59) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.scala:17) ~[scala-library-2.13.8.jar:?]
	at org.apache.spark.storage.BlockManagerStorageEndpoint.$anonfun$doAsync$1(BlockManagerStorageEndpoint.scala:89) ~[spark-core_2.13-3.3.0.jar:3.3.0]
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:678) ~[scala-library-2.13.8.jar:?]
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467) ~[scala-library-2.13.8.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_332]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_332]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_332]
2022-08-18 14:39:54,548 WARN c.g.f.Day18Logging [main] This is a warning
2022-08-18 14:39:54,558 ERROR c.g.f.Day18Logging [main] This is an error!
